{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2862: DtypeWarning: Columns (9,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1: self.dataframe.columns: Index(['tourney_id', 'tourney_name', 'surface', 'draw_size', 'tourney_level',\n",
      "       'tourney_date', 'match_num', 'winner_id', 'winner_seed', 'winner_entry',\n",
      "       'winner_name', 'winner_hand', 'winner_ht', 'winner_ioc', 'winner_age',\n",
      "       'winner_rank', 'winner_rank_points', 'loser_id', 'loser_seed',\n",
      "       'loser_entry', 'loser_name', 'loser_hand', 'loser_ht', 'loser_ioc',\n",
      "       'loser_age', 'loser_rank', 'loser_rank_points', 'score', 'best_of',\n",
      "       'round', 'minutes', 'w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon',\n",
      "       'w_2ndWon', 'w_SvGms', 'w_bpSaved', 'w_bpFaced', 'l_ace', 'l_df',\n",
      "       'l_svpt', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved',\n",
      "       'l_bpFaced'],\n",
      "      dtype='object')\n",
      "overall_preproc_operations target_tag: best_of\n",
      "Index(['tourney_id', 'tourney_name', 'surface', 'draw_size', 'tourney_level',\n",
      "       'tourney_date', 'match_num', 'winner_id', 'winner_seed', 'winner_entry',\n",
      "       'winner_name', 'winner_hand', 'winner_ht', 'winner_ioc', 'winner_age',\n",
      "       'winner_rank', 'winner_rank_points', 'loser_id', 'loser_seed',\n",
      "       'loser_entry', 'loser_name', 'loser_hand', 'loser_ht', 'loser_ioc',\n",
      "       'loser_age', 'loser_rank', 'loser_rank_points', 'score', 'best_of',\n",
      "       'round', 'minutes', 'w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon',\n",
      "       'w_2ndWon', 'w_SvGms', 'w_bpSaved', 'w_bpFaced', 'l_ace', 'l_df',\n",
      "       'l_svpt', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved',\n",
      "       'l_bpFaced'],\n",
      "      dtype='object')\n",
      "number of dataframe rows pre-proc step2: 164028\n",
      "list_nominal_cols ['surface', 'winner_hand', 'loser_hand']\n",
      "one_hot         surface_Carpet  surface_Clay  surface_Grass  surface_Hard\n",
      "0                    0             0              1             0\n",
      "1                    0             0              1             0\n",
      "2                    0             0              1             0\n",
      "3                    0             0              1             0\n",
      "4                    0             0              1             0\n",
      "5                    0             0              1             0\n",
      "6                    0             0              1             0\n",
      "7                    0             0              1             0\n",
      "8                    0             0              1             0\n",
      "9                    0             0              1             0\n",
      "10                   0             0              1             0\n",
      "11                   0             0              1             0\n",
      "12                   0             0              1             0\n",
      "13                   0             0              1             0\n",
      "14                   0             0              1             0\n",
      "15                   0             0              1             0\n",
      "16                   0             0              1             0\n",
      "17                   0             0              1             0\n",
      "18                   0             0              1             0\n",
      "19                   0             0              1             0\n",
      "20                   0             0              1             0\n",
      "21                   0             0              1             0\n",
      "22                   0             0              1             0\n",
      "23                   0             0              1             0\n",
      "24                   0             0              1             0\n",
      "25                   0             0              1             0\n",
      "26                   0             0              1             0\n",
      "27                   0             0              1             0\n",
      "28                   0             0              1             0\n",
      "29                   0             0              1             0\n",
      "...                ...           ...            ...           ...\n",
      "163998               0             1              0             0\n",
      "163999               0             1              0             0\n",
      "164000               0             1              0             0\n",
      "164001               0             0              0             1\n",
      "164002               0             0              0             1\n",
      "164003               0             0              0             1\n",
      "164004               0             0              0             1\n",
      "164005               0             0              0             1\n",
      "164006               0             0              0             1\n",
      "164007               0             0              0             1\n",
      "164008               0             0              0             1\n",
      "164009               0             0              0             1\n",
      "164010               0             0              0             1\n",
      "164011               0             0              0             1\n",
      "164012               0             0              0             1\n",
      "164013               0             0              0             1\n",
      "164014               0             0              0             1\n",
      "164015               0             0              0             1\n",
      "164016               0             0              0             1\n",
      "164017               0             0              0             1\n",
      "164018               0             0              0             1\n",
      "164019               0             0              0             1\n",
      "164020               0             0              0             1\n",
      "164021               0             0              0             1\n",
      "164022               0             0              0             1\n",
      "164023               0             0              0             1\n",
      "164024               0             0              0             1\n",
      "164025               0             0              0             1\n",
      "164026               0             0              0             1\n",
      "164027               0             0              0             1\n",
      "\n",
      "[164028 rows x 4 columns]\n",
      "one_hot         winner_hand_L  winner_hand_R  winner_hand_U\n",
      "0                   0              1              0\n",
      "1                   0              1              0\n",
      "2                   0              1              0\n",
      "3                   0              1              0\n",
      "4                   0              1              0\n",
      "5                   0              1              0\n",
      "6                   0              1              0\n",
      "7                   0              1              0\n",
      "8                   0              1              0\n",
      "9                   0              1              0\n",
      "10                  0              1              0\n",
      "11                  0              1              0\n",
      "12                  1              0              0\n",
      "13                  0              1              0\n",
      "14                  1              0              0\n",
      "15                  0              1              0\n",
      "16                  0              1              0\n",
      "17                  0              1              0\n",
      "18                  0              1              0\n",
      "19                  0              1              0\n",
      "20                  0              1              0\n",
      "21                  0              1              0\n",
      "22                  0              1              0\n",
      "23                  0              1              0\n",
      "24                  0              1              0\n",
      "25                  0              1              0\n",
      "26                  0              1              0\n",
      "27                  0              1              0\n",
      "28                  0              1              0\n",
      "29                  0              1              0\n",
      "...               ...            ...            ...\n",
      "163998              0              1              0\n",
      "163999              0              1              0\n",
      "164000              0              1              0\n",
      "164001              0              1              0\n",
      "164002              0              1              0\n",
      "164003              0              1              0\n",
      "164004              1              0              0\n",
      "164005              0              1              0\n",
      "164006              0              1              0\n",
      "164007              0              1              0\n",
      "164008              0              1              0\n",
      "164009              0              1              0\n",
      "164010              0              1              0\n",
      "164011              1              0              0\n",
      "164012              0              1              0\n",
      "164013              0              1              0\n",
      "164014              0              1              0\n",
      "164015              0              1              0\n",
      "164016              0              1              0\n",
      "164017              0              1              0\n",
      "164018              0              1              0\n",
      "164019              0              1              0\n",
      "164020              0              1              0\n",
      "164021              0              1              0\n",
      "164022              0              1              0\n",
      "164023              0              1              0\n",
      "164024              0              1              0\n",
      "164025              0              1              0\n",
      "164026              0              1              0\n",
      "164027              0              1              0\n",
      "\n",
      "[164028 rows x 3 columns]\n",
      "one_hot         loser_hand_L  loser_hand_R  loser_hand_U\n",
      "0                  0             1             0\n",
      "1                  0             1             0\n",
      "2                  0             1             0\n",
      "3                  0             1             0\n",
      "4                  0             1             0\n",
      "5                  0             1             0\n",
      "6                  0             1             0\n",
      "7                  0             1             0\n",
      "8                  0             1             0\n",
      "9                  0             1             0\n",
      "10                 0             1             0\n",
      "11                 0             1             0\n",
      "12                 0             1             0\n",
      "13                 0             1             0\n",
      "14                 0             1             0\n",
      "15                 0             1             0\n",
      "16                 0             1             0\n",
      "17                 0             1             0\n",
      "18                 0             1             0\n",
      "19                 0             1             0\n",
      "20                 0             1             0\n",
      "21                 0             1             0\n",
      "22                 0             1             0\n",
      "23                 0             1             0\n",
      "24                 0             1             0\n",
      "25                 0             1             0\n",
      "26                 0             1             0\n",
      "27                 0             1             0\n",
      "28                 0             1             0\n",
      "29                 0             1             0\n",
      "...              ...           ...           ...\n",
      "163998             0             1             0\n",
      "163999             0             1             0\n",
      "164000             1             0             0\n",
      "164001             0             1             0\n",
      "164002             0             1             0\n",
      "164003             0             1             0\n",
      "164004             1             0             0\n",
      "164005             1             0             0\n",
      "164006             0             1             0\n",
      "164007             0             1             0\n",
      "164008             1             0             0\n",
      "164009             1             0             0\n",
      "164010             0             1             0\n",
      "164011             0             1             0\n",
      "164012             0             1             0\n",
      "164013             0             1             0\n",
      "164014             0             1             0\n",
      "164015             0             1             0\n",
      "164016             0             1             0\n",
      "164017             0             1             0\n",
      "164018             1             0             0\n",
      "164019             1             0             0\n",
      "164020             0             1             0\n",
      "164021             0             1             0\n",
      "164022             0             1             0\n",
      "164023             0             1             0\n",
      "164024             0             1             0\n",
      "164025             0             1             0\n",
      "164026             1             0             0\n",
      "164027             0             0             1\n",
      "\n",
      "[164028 rows x 3 columns]\n",
      "dataframe columns after nominal_features_one_hot_encoder Index(['draw_size', 'match_num', 'winner_ht', 'winner_age', 'winner_rank',\n",
      "       'winner_rank_points', 'loser_ht', 'loser_age', 'loser_rank',\n",
      "       'loser_rank_points', 'best_of', 'minutes', 'surface_Carpet',\n",
      "       'surface_Clay', 'surface_Grass', 'surface_Hard', 'winner_hand_L',\n",
      "       'winner_hand_R', 'winner_hand_U', 'loser_hand_L', 'loser_hand_R',\n",
      "       'loser_hand_U'],\n",
      "      dtype='object')\n",
      "number of non NaN dataframe per column pre-proc step3: draw_size             163965\n",
      "match_num             163965\n",
      "winner_ht             145980\n",
      "winner_age            160522\n",
      "winner_rank           139316\n",
      "winner_rank_points    139316\n",
      "loser_ht              134717\n",
      "loser_age             157406\n",
      "loser_rank            136168\n",
      "loser_rank_points     136168\n",
      "best_of               163965\n",
      "minutes                74877\n",
      "surface_Carpet        164028\n",
      "surface_Clay          164028\n",
      "surface_Grass         164028\n",
      "surface_Hard          164028\n",
      "winner_hand_L         164028\n",
      "winner_hand_R         164028\n",
      "winner_hand_U         164028\n",
      "loser_hand_L          164028\n",
      "loser_hand_R          164028\n",
      "loser_hand_U          164028\n",
      "dtype: int64\n",
      "number of dataframe rows pre-proc step3: 164028\n",
      "number of non NaN dataframe per colmumn pre-proc step3: draw_size             68905\n",
      "match_num             68905\n",
      "winner_ht             68905\n",
      "winner_age            68905\n",
      "winner_rank           68905\n",
      "winner_rank_points    68905\n",
      "loser_ht              68905\n",
      "loser_age             68905\n",
      "loser_rank            68905\n",
      "loser_rank_points     68905\n",
      "best_of               68905\n",
      "minutes               68905\n",
      "surface_Carpet        68905\n",
      "surface_Clay          68905\n",
      "surface_Grass         68905\n",
      "surface_Hard          68905\n",
      "winner_hand_L         68905\n",
      "winner_hand_R         68905\n",
      "winner_hand_U         68905\n",
      "loser_hand_L          68905\n",
      "loser_hand_R          68905\n",
      "loser_hand_U          68905\n",
      "dtype: int64\n",
      "number of dataframe rows pre-proc step4: 68905\n",
      "new_tennis_df columns Index(['draw_size', 'match_num', 'winner_ht', 'winner_age', 'winner_rank',\n",
      "       'winner_rank_points', 'loser_ht', 'loser_age', 'loser_rank',\n",
      "       'loser_rank_points', 'best_of', 'minutes', 'surface_Carpet',\n",
      "       'surface_Clay', 'surface_Grass', 'surface_Hard', 'winner_hand_L',\n",
      "       'winner_hand_R', 'winner_hand_U', 'loser_hand_L', 'loser_hand_R',\n",
      "       'loser_hand_U'],\n",
      "      dtype='object')\n",
      "normalize_numerical_variables self.numeric_columns Index(['draw_size', 'match_num', 'winner_ht', 'winner_age', 'winner_rank',\n",
      "       'winner_rank_points', 'loser_ht', 'loser_age', 'loser_rank',\n",
      "       'loser_rank_points', 'best_of', 'minutes', 'surface_Carpet',\n",
      "       'surface_Clay', 'surface_Grass', 'surface_Hard', 'winner_hand_L',\n",
      "       'winner_hand_R', 'winner_hand_U', 'loser_hand_L', 'loser_hand_R',\n",
      "       'loser_hand_U'],\n",
      "      dtype='object')\n",
      "column draw_size\n",
      "column values AFTER [0.22580645 0.22580645 0.22580645 ... 0.         0.         0.        ]\n",
      "column match_num\n",
      "column values AFTER [0.         0.00314465 0.00628931 ... 0.         0.00943396 0.        ]\n",
      "column winner_ht\n",
      "column values AFTER [0.33333333 0.37777778 0.11111111 ... 0.33333333 0.66666667 0.48888889]\n",
      "column winner_age\n",
      "column values AFTER [0.23032874 0.44050901 0.26839873 ... 0.66076352 0.41760339 0.33022269]\n",
      "column winner_rank\n",
      "column values AFTER [0.02060528 0.2833226  0.13329041 ... 0.03670316 0.08499678 0.01223439]\n",
      "column winner_rank_points\n",
      "column values AFTER [0.04631542 0.00206502 0.00837808 ... 0.04637442 0.02578323 0.10938698]\n",
      "column loser_ht\n",
      "column values AFTER [0.375      0.47916667 0.3125     ... 0.375      0.3125     0.52083333]\n",
      "column loser_age\n",
      "column values AFTER [0.49211112 0.35485432 0.62636724 ... 0.627432   0.39405672 0.70157778]\n",
      "column loser_rank\n",
      "column values AFTER [0.11428571 0.31257143 0.12685714 ... 0.016      0.02514286 0.08285714]\n",
      "column loser_rank_points\n",
      "column values AFTER [0.00896808 0.00123901 0.00696206 ... 0.08283675 0.06077055 0.02436722]\n",
      "column best_of\n",
      "column values AFTER [0. 0. 0. ... 1. 1. 1.]\n",
      "column minutes\n",
      "column values AFTER [ 59.  55.  75. ... 233. 203. 118.]\n",
      "column surface_Carpet\n",
      "column values AFTER [0. 0. 0. ... 0. 0. 0.]\n",
      "column surface_Clay\n",
      "column values AFTER [1. 1. 1. ... 0. 0. 0.]\n",
      "column surface_Grass\n",
      "column values AFTER [0. 0. 0. ... 0. 0. 0.]\n",
      "column surface_Hard\n",
      "column values AFTER [0. 0. 0. ... 1. 1. 1.]\n",
      "column winner_hand_L\n",
      "column values AFTER [0. 0. 0. ... 0. 0. 0.]\n",
      "column winner_hand_R\n",
      "column values AFTER [1. 1. 1. ... 1. 1. 1.]\n",
      "column winner_hand_U\n",
      "column values AFTER [0. 0. 0. ... 0. 0. 0.]\n",
      "column loser_hand_L\n",
      "column values AFTER [0. 0. 0. ... 0. 0. 0.]\n",
      "column loser_hand_R\n",
      "column values AFTER [1. 1. 1. ... 1. 1. 1.]\n",
      "column loser_hand_U\n",
      "column values AFTER [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize_numerical_variables self.numeric_columns Index(['draw_size', 'match_num', 'winner_ht', 'winner_age', 'winner_rank',\n",
      "       'winner_rank_points', 'loser_ht', 'loser_age', 'loser_rank',\n",
      "       'loser_rank_points', 'best_of', 'minutes', 'surface_Carpet',\n",
      "       'surface_Clay', 'surface_Grass', 'surface_Hard', 'winner_hand_L',\n",
      "       'winner_hand_R', 'winner_hand_U', 'loser_hand_L', 'loser_hand_R',\n",
      "       'loser_hand_U'],\n",
      "      dtype='object')\n",
      "self.dataframe after normalizing_numerical variables         draw_size  match_num  winner_ht  winner_age  winner_rank  \\\n",
      "77000    0.225806   0.000000   0.333333    0.230329     0.020605   \n",
      "77001    0.225806   0.003145   0.377778    0.440509     0.283323   \n",
      "77002    0.225806   0.006289   0.111111    0.268399     0.133290   \n",
      "77003    0.225806   0.009434   0.444444    0.288229     0.090792   \n",
      "77004    0.225806   0.012579   0.222222    0.221527     0.029620   \n",
      "77005    0.225806   0.015723   0.377778    0.405832     0.079202   \n",
      "77006    0.225806   0.018868   0.600000    0.318558     0.121056   \n",
      "77007    0.225806   0.022013   0.266667    0.208165     0.032196   \n",
      "77008    0.225806   0.025157   0.488889    0.369141     0.068899   \n",
      "77009    0.225806   0.028302   0.444444    0.282927     0.092724   \n",
      "77010    0.225806   0.031447   0.488889    0.448356     0.094656   \n",
      "77011    0.225806   0.034591   0.600000    0.172110     0.027044   \n",
      "77012    0.225806   0.037736   0.600000    0.212195     0.073406   \n",
      "77013    0.225806   0.040881   0.377778    0.399258     0.110753   \n",
      "77014    0.225806   0.044025   0.444444    0.214528     0.115261   \n",
      "77015    0.225806   0.047170   0.266667    0.429480     0.018674   \n",
      "77016    0.225806   0.050314   0.333333    0.230329     0.020605   \n",
      "77017    0.225806   0.053459   0.444444    0.288229     0.090792   \n",
      "77018    0.225806   0.056604   0.222222    0.221527     0.029620   \n",
      "77019    0.225806   0.059748   0.266667    0.208165     0.032196   \n",
      "77020    0.225806   0.062893   0.488889    0.369141     0.068899   \n",
      "77021    0.225806   0.066038   0.600000    0.172110     0.027044   \n",
      "77022    0.225806   0.069182   0.377778    0.399258     0.110753   \n",
      "77023    0.225806   0.072327   0.444444    0.214528     0.115261   \n",
      "77025    0.225806   0.078616   0.266667    0.208165     0.032196   \n",
      "77026    0.225806   0.081761   0.488889    0.369141     0.068899   \n",
      "77027    0.225806   0.084906   0.444444    0.214528     0.115261   \n",
      "77028    0.225806   0.088050   0.333333    0.230329     0.020605   \n",
      "77029    0.225806   0.091195   0.444444    0.214528     0.115261   \n",
      "77030    0.225806   0.094340   0.333333    0.230329     0.020605   \n",
      "...           ...        ...        ...         ...          ...   \n",
      "163878   1.000000   0.622642   0.333333    0.434783     0.002576   \n",
      "163879   1.000000   0.625786   0.444444    0.618982     0.001932   \n",
      "163880   1.000000   0.628931   0.600000    0.661506     0.056665   \n",
      "163881   1.000000   0.632075   0.555556    0.616861     0.007083   \n",
      "163882   1.000000   0.635220   0.266667    0.419406     0.032196   \n",
      "163883   1.000000   0.638365   0.666667    0.563627     0.003220   \n",
      "163886   1.000000   0.647799   0.733333    0.396288     0.001288   \n",
      "163888   1.000000   0.654088   0.000000    0.398409     0.006439   \n",
      "163889   1.000000   0.657233   0.555556    0.381442     0.009015   \n",
      "163891   1.000000   0.663522   0.600000    0.525981     0.031552   \n",
      "163892   1.000000   0.666667   0.488889    0.759809     0.010303   \n",
      "163893   1.000000   0.669811   0.444444    0.618982     0.001932   \n",
      "163894   1.000000   0.672956   0.555556    0.616861     0.007083   \n",
      "163895   1.000000   0.676101   0.488889    0.573171     0.005151   \n",
      "163898   1.000000   0.685535   0.555556    0.381442     0.009015   \n",
      "163899   1.000000   0.688679   0.488889    0.759809     0.010303   \n",
      "163900   1.000000   0.691824   0.444444    0.618982     0.001932   \n",
      "163901   1.000000   0.694969   0.488889    0.573171     0.005151   \n",
      "163902   1.000000   0.698113   0.555556    0.381442     0.009015   \n",
      "163903   1.000000   0.701258   0.488889    0.759809     0.010303   \n",
      "163904   1.000000   0.704403   0.488889    0.573171     0.005151   \n",
      "163905   1.000000   0.707547   0.488889    0.759809     0.010303   \n",
      "163922   0.000000   0.003145   0.333333    0.401273     0.048294   \n",
      "163933   0.000000   0.000000   0.600000    0.454401     0.022537   \n",
      "163979   0.000000   0.009434   0.600000    0.681866     0.262073   \n",
      "163998   0.000000   0.003145   0.600000    0.662990     0.043142   \n",
      "163999   0.000000   0.009434   0.444444    0.703606     0.051513   \n",
      "164001   0.000000   0.000000   0.333333    0.660764     0.036703   \n",
      "164007   0.000000   0.009434   0.666667    0.417603     0.084997   \n",
      "164024   0.000000   0.000000   0.488889    0.330223     0.012234   \n",
      "\n",
      "        winner_rank_points  loser_ht  loser_age  loser_rank  \\\n",
      "77000             0.046315  0.375000   0.492111    0.114286   \n",
      "77001             0.002065  0.479167   0.354854    0.312571   \n",
      "77002             0.008378  0.312500   0.626367    0.126857   \n",
      "77003             0.014632  0.625000   0.275772    0.068571   \n",
      "77004             0.037229  0.312500   0.171523    0.146286   \n",
      "77005             0.017641  0.270833   0.287194    0.080000   \n",
      "77006             0.009558  0.479167   0.191269    0.079429   \n",
      "77007             0.034987  0.520833   0.301229    0.091429   \n",
      "77008             0.020532  0.270833   0.412932    0.112000   \n",
      "77009             0.013983  0.520833   0.285645    0.090286   \n",
      "77010             0.013806  0.416667   0.196206    0.081714   \n",
      "77011             0.039825  0.270833   0.420869    0.622286   \n",
      "77012             0.019765  0.375000   0.468299    0.108000   \n",
      "77013             0.010502  0.520833   0.255154    0.224000   \n",
      "77014             0.010207  0.479167   0.315555    0.198286   \n",
      "77015             0.049560  0.208333   0.532669    0.076000   \n",
      "77016             0.046315  0.416667   0.411964    0.251429   \n",
      "77017             0.014632  0.166667   0.254864    0.118286   \n",
      "77018             0.037229  0.416667   0.380312    0.070286   \n",
      "77019             0.034987  0.625000   0.300649    0.107429   \n",
      "77020             0.020532  0.479167   0.268125    0.082286   \n",
      "77021             0.039825  0.520833   0.419127    0.084000   \n",
      "77022             0.010502  0.625000   0.203562    0.065143   \n",
      "77023             0.010207  0.312500   0.401897    0.016571   \n",
      "77025             0.034987  0.270833   0.212080    0.026286   \n",
      "77026             0.020532  0.625000   0.166973    0.024000   \n",
      "77027             0.010207  0.416667   0.374310    0.098286   \n",
      "77028             0.046315  0.312500   0.199884    0.028571   \n",
      "77029             0.010207  0.520833   0.346820    0.061143   \n",
      "77030             0.046315  0.479167   0.205692    0.102286   \n",
      "...                    ...       ...        ...         ...   \n",
      "163878            0.295534  0.520833   0.482915    0.068571   \n",
      "163879            0.304089  0.687500   0.543994    0.019429   \n",
      "163880            0.037406  0.375000   0.611654    0.040000   \n",
      "163881            0.147737  0.520833   0.309941    0.010857   \n",
      "163882            0.052215  0.687500   0.307327    0.014857   \n",
      "163883            0.213818  0.375000   0.626077    0.018286   \n",
      "163886            0.312054  0.479167   0.583680    0.013714   \n",
      "163888            0.162192  1.000000   0.789759    0.011429   \n",
      "163889            0.125907  0.520833   0.531604    0.009714   \n",
      "163891            0.052687  0.625000   0.499564    0.000000   \n",
      "163892            0.116762  0.375000   0.406737    0.002286   \n",
      "163893            0.304089  0.625000   0.613687    0.050286   \n",
      "163894            0.147737  0.312500   0.392702    0.028571   \n",
      "163895            0.188448  0.687500   0.524344    0.002857   \n",
      "163898            0.125907  0.583333   0.523763    0.066286   \n",
      "163899            0.116762  0.625000   0.489982    0.028000   \n",
      "163900            0.304089  0.583333   0.572936    0.006286   \n",
      "163901            0.188448  0.750000   0.371600    0.001143   \n",
      "163902            0.125907  0.062500   0.373536    0.005714   \n",
      "163903            0.116762  0.479167   0.574872    0.001714   \n",
      "163904            0.188448  0.583333   0.358049    0.008000   \n",
      "163905            0.116762  0.520833   0.533056    0.004571   \n",
      "163922            0.040356  0.312500   0.575549    0.042286   \n",
      "163933            0.072512  0.416667   0.452425    0.161714   \n",
      "163979            0.006077  0.520833   0.465105    0.389143   \n",
      "163998            0.042716  0.479167   0.652115    0.045714   \n",
      "163999            0.039353  0.479167   0.692285    0.024000   \n",
      "164001            0.046374  0.375000   0.627432    0.016000   \n",
      "164007            0.025783  0.312500   0.394057    0.025143   \n",
      "164024            0.109387  0.520833   0.701578    0.082857   \n",
      "\n",
      "        loser_rank_points      ...       surface_Carpet  surface_Clay  \\\n",
      "77000            0.008968      ...                  0.0           1.0   \n",
      "77001            0.001239      ...                  0.0           1.0   \n",
      "77002            0.006962      ...                  0.0           1.0   \n",
      "77003            0.018526      ...                  0.0           1.0   \n",
      "77004            0.005369      ...                  0.0           1.0   \n",
      "77005            0.014868      ...                  0.0           1.0   \n",
      "77006            0.015222      ...                  0.0           1.0   \n",
      "77007            0.012095      ...                  0.0           1.0   \n",
      "77008            0.009263      ...                  0.0           1.0   \n",
      "77009            0.012626      ...                  0.0           1.0   \n",
      "77010            0.014337      ...                  0.0           1.0   \n",
      "77011            0.000000      ...                  0.0           1.0   \n",
      "77012            0.009558      ...                  0.0           1.0   \n",
      "77013            0.002714      ...                  0.0           1.0   \n",
      "77014            0.003304      ...                  0.0           1.0   \n",
      "77015            0.016402      ...                  0.0           1.0   \n",
      "77016            0.002065      ...                  0.0           1.0   \n",
      "77017            0.008378      ...                  0.0           1.0   \n",
      "77018            0.017641      ...                  0.0           1.0   \n",
      "77019            0.009558      ...                  0.0           1.0   \n",
      "77020            0.013983      ...                  0.0           1.0   \n",
      "77021            0.013806      ...                  0.0           1.0   \n",
      "77022            0.019765      ...                  0.0           1.0   \n",
      "77023            0.049560      ...                  0.0           1.0   \n",
      "77025            0.037229      ...                  0.0           1.0   \n",
      "77026            0.039825      ...                  0.0           1.0   \n",
      "77027            0.010502      ...                  0.0           1.0   \n",
      "77028            0.034987      ...                  0.0           1.0   \n",
      "77029            0.020532      ...                  0.0           1.0   \n",
      "77030            0.010207      ...                  0.0           1.0   \n",
      "...                   ...      ...                  ...           ...   \n",
      "163878           0.028615      ...                  0.0           0.0   \n",
      "163879           0.072217      ...                  0.0           0.0   \n",
      "163880           0.041654      ...                  0.0           0.0   \n",
      "163881           0.106732      ...                  0.0           0.0   \n",
      "163882           0.083722      ...                  0.0           0.0   \n",
      "163883           0.078117      ...                  0.0           0.0   \n",
      "163886           0.093457      ...                  0.0           0.0   \n",
      "163888           0.105847      ...                  0.0           0.0   \n",
      "163889           0.111157      ...                  0.0           0.0   \n",
      "163891           0.740988      ...                  0.0           0.0   \n",
      "163892           0.295534      ...                  0.0           0.0   \n",
      "163893           0.037406      ...                  0.0           0.0   \n",
      "163894           0.052215      ...                  0.0           0.0   \n",
      "163895           0.213818      ...                  0.0           0.0   \n",
      "163898           0.029323      ...                  0.0           0.0   \n",
      "163899           0.052687      ...                  0.0           0.0   \n",
      "163900           0.147737      ...                  0.0           0.0   \n",
      "163901           0.312054      ...                  0.0           0.0   \n",
      "163902           0.162192      ...                  0.0           0.0   \n",
      "163903           0.304089      ...                  0.0           0.0   \n",
      "163904           0.125907      ...                  0.0           0.0   \n",
      "163905           0.188448      ...                  0.0           0.0   \n",
      "163922           0.040415      ...                  0.0           1.0   \n",
      "163933           0.010502      ...                  0.0           0.0   \n",
      "163979           0.002065      ...                  1.0           0.0   \n",
      "163998           0.039353      ...                  0.0           1.0   \n",
      "163999           0.061420      ...                  0.0           1.0   \n",
      "164001           0.082837      ...                  0.0           0.0   \n",
      "164007           0.060771      ...                  0.0           0.0   \n",
      "164024           0.024367      ...                  0.0           0.0   \n",
      "\n",
      "        surface_Grass  surface_Hard  winner_hand_L  winner_hand_R  \\\n",
      "77000             0.0           0.0            0.0            1.0   \n",
      "77001             0.0           0.0            0.0            1.0   \n",
      "77002             0.0           0.0            0.0            1.0   \n",
      "77003             0.0           0.0            0.0            1.0   \n",
      "77004             0.0           0.0            1.0            0.0   \n",
      "77005             0.0           0.0            0.0            1.0   \n",
      "77006             0.0           0.0            0.0            1.0   \n",
      "77007             0.0           0.0            0.0            1.0   \n",
      "77008             0.0           0.0            1.0            0.0   \n",
      "77009             0.0           0.0            1.0            0.0   \n",
      "77010             0.0           0.0            1.0            0.0   \n",
      "77011             0.0           0.0            0.0            1.0   \n",
      "77012             0.0           0.0            1.0            0.0   \n",
      "77013             0.0           0.0            0.0            1.0   \n",
      "77014             0.0           0.0            0.0            1.0   \n",
      "77015             0.0           0.0            0.0            1.0   \n",
      "77016             0.0           0.0            0.0            1.0   \n",
      "77017             0.0           0.0            0.0            1.0   \n",
      "77018             0.0           0.0            1.0            0.0   \n",
      "77019             0.0           0.0            0.0            1.0   \n",
      "77020             0.0           0.0            1.0            0.0   \n",
      "77021             0.0           0.0            0.0            1.0   \n",
      "77022             0.0           0.0            0.0            1.0   \n",
      "77023             0.0           0.0            0.0            1.0   \n",
      "77025             0.0           0.0            0.0            1.0   \n",
      "77026             0.0           0.0            1.0            0.0   \n",
      "77027             0.0           0.0            0.0            1.0   \n",
      "77028             0.0           0.0            0.0            1.0   \n",
      "77029             0.0           0.0            0.0            1.0   \n",
      "77030             0.0           0.0            0.0            1.0   \n",
      "...               ...           ...            ...            ...   \n",
      "163878            0.0           1.0            0.0            1.0   \n",
      "163879            0.0           1.0            0.0            1.0   \n",
      "163880            0.0           1.0            0.0            1.0   \n",
      "163881            0.0           1.0            0.0            1.0   \n",
      "163882            0.0           1.0            0.0            1.0   \n",
      "163883            0.0           1.0            0.0            1.0   \n",
      "163886            0.0           1.0            0.0            1.0   \n",
      "163888            0.0           1.0            0.0            1.0   \n",
      "163889            0.0           1.0            0.0            1.0   \n",
      "163891            0.0           1.0            1.0            0.0   \n",
      "163892            0.0           1.0            0.0            1.0   \n",
      "163893            0.0           1.0            0.0            1.0   \n",
      "163894            0.0           1.0            0.0            1.0   \n",
      "163895            0.0           1.0            1.0            0.0   \n",
      "163898            0.0           1.0            0.0            1.0   \n",
      "163899            0.0           1.0            0.0            1.0   \n",
      "163900            0.0           1.0            0.0            1.0   \n",
      "163901            0.0           1.0            1.0            0.0   \n",
      "163902            0.0           1.0            0.0            1.0   \n",
      "163903            0.0           1.0            0.0            1.0   \n",
      "163904            0.0           1.0            1.0            0.0   \n",
      "163905            0.0           1.0            0.0            1.0   \n",
      "163922            0.0           0.0            0.0            1.0   \n",
      "163933            0.0           1.0            1.0            0.0   \n",
      "163979            0.0           0.0            0.0            1.0   \n",
      "163998            0.0           0.0            0.0            1.0   \n",
      "163999            0.0           0.0            0.0            1.0   \n",
      "164001            0.0           1.0            0.0            1.0   \n",
      "164007            0.0           1.0            0.0            1.0   \n",
      "164024            0.0           1.0            0.0            1.0   \n",
      "\n",
      "        winner_hand_U  loser_hand_L  loser_hand_R  loser_hand_U  \n",
      "77000             0.0           0.0           1.0           0.0  \n",
      "77001             0.0           0.0           1.0           0.0  \n",
      "77002             0.0           0.0           1.0           0.0  \n",
      "77003             0.0           1.0           0.0           0.0  \n",
      "77004             0.0           0.0           1.0           0.0  \n",
      "77005             0.0           0.0           1.0           0.0  \n",
      "77006             0.0           0.0           1.0           0.0  \n",
      "77007             0.0           0.0           1.0           0.0  \n",
      "77008             0.0           0.0           1.0           0.0  \n",
      "77009             0.0           0.0           1.0           0.0  \n",
      "77010             0.0           0.0           1.0           0.0  \n",
      "77011             0.0           0.0           1.0           0.0  \n",
      "77012             0.0           1.0           0.0           0.0  \n",
      "77013             0.0           0.0           1.0           0.0  \n",
      "77014             0.0           0.0           1.0           0.0  \n",
      "77015             0.0           0.0           1.0           0.0  \n",
      "77016             0.0           0.0           1.0           0.0  \n",
      "77017             0.0           0.0           1.0           0.0  \n",
      "77018             0.0           0.0           1.0           0.0  \n",
      "77019             0.0           0.0           1.0           0.0  \n",
      "77020             0.0           1.0           0.0           0.0  \n",
      "77021             0.0           1.0           0.0           0.0  \n",
      "77022             0.0           1.0           0.0           0.0  \n",
      "77023             0.0           0.0           1.0           0.0  \n",
      "77025             0.0           1.0           0.0           0.0  \n",
      "77026             0.0           0.0           1.0           0.0  \n",
      "77027             0.0           0.0           1.0           0.0  \n",
      "77028             0.0           0.0           1.0           0.0  \n",
      "77029             0.0           1.0           0.0           0.0  \n",
      "77030             0.0           0.0           1.0           0.0  \n",
      "...               ...           ...           ...           ...  \n",
      "163878            0.0           0.0           1.0           0.0  \n",
      "163879            0.0           0.0           1.0           0.0  \n",
      "163880            0.0           0.0           1.0           0.0  \n",
      "163881            0.0           0.0           1.0           0.0  \n",
      "163882            0.0           0.0           1.0           0.0  \n",
      "163883            0.0           0.0           1.0           0.0  \n",
      "163886            0.0           0.0           1.0           0.0  \n",
      "163888            0.0           0.0           1.0           0.0  \n",
      "163889            0.0           0.0           1.0           0.0  \n",
      "163891            0.0           0.0           1.0           0.0  \n",
      "163892            0.0           0.0           1.0           0.0  \n",
      "163893            0.0           0.0           1.0           0.0  \n",
      "163894            0.0           0.0           1.0           0.0  \n",
      "163895            0.0           0.0           1.0           0.0  \n",
      "163898            0.0           0.0           1.0           0.0  \n",
      "163899            0.0           1.0           0.0           0.0  \n",
      "163900            0.0           0.0           1.0           0.0  \n",
      "163901            0.0           0.0           1.0           0.0  \n",
      "163902            0.0           0.0           1.0           0.0  \n",
      "163903            0.0           0.0           1.0           0.0  \n",
      "163904            0.0           0.0           1.0           0.0  \n",
      "163905            0.0           1.0           0.0           0.0  \n",
      "163922            0.0           0.0           1.0           0.0  \n",
      "163933            0.0           0.0           1.0           0.0  \n",
      "163979            0.0           0.0           1.0           0.0  \n",
      "163998            0.0           0.0           1.0           0.0  \n",
      "163999            0.0           0.0           1.0           0.0  \n",
      "164001            0.0           0.0           1.0           0.0  \n",
      "164007            0.0           0.0           1.0           0.0  \n",
      "164024            0.0           0.0           1.0           0.0  \n",
      "\n",
      "[68905 rows x 22 columns]\n",
      "build_dataset_target minutes\n",
      "build_target_options target_label: minutes\n",
      "build_target_options self.dataframe[target_label]: 77000      59.0\n",
      "77001      55.0\n",
      "77002      75.0\n",
      "77003     100.0\n",
      "77004      55.0\n",
      "77005     112.0\n",
      "77006     160.0\n",
      "77007      76.0\n",
      "77008      45.0\n",
      "77009      65.0\n",
      "77010      70.0\n",
      "77011      85.0\n",
      "77012      85.0\n",
      "77013     110.0\n",
      "77014      92.0\n",
      "77015     140.0\n",
      "77016     130.0\n",
      "77017      55.0\n",
      "77018     119.0\n",
      "77019      91.0\n",
      "77020     130.0\n",
      "77021      77.0\n",
      "77022      80.0\n",
      "77023      83.0\n",
      "77025      99.0\n",
      "77026     180.0\n",
      "77027      85.0\n",
      "77028      80.0\n",
      "77029      75.0\n",
      "77030     105.0\n",
      "          ...  \n",
      "163878    131.0\n",
      "163879    152.0\n",
      "163880    187.0\n",
      "163881    213.0\n",
      "163882    168.0\n",
      "163883    115.0\n",
      "163886    154.0\n",
      "163888     87.0\n",
      "163889    122.0\n",
      "163891    213.0\n",
      "163892    203.0\n",
      "163893    163.0\n",
      "163894    173.0\n",
      "163895    175.0\n",
      "163898    144.0\n",
      "163899     92.0\n",
      "163900    134.0\n",
      "163901    164.0\n",
      "163902    132.0\n",
      "163903    184.0\n",
      "163904    296.0\n",
      "163905    217.0\n",
      "163922    146.0\n",
      "163933    150.0\n",
      "163979    127.0\n",
      "163998    178.0\n",
      "163999    254.0\n",
      "164001    233.0\n",
      "164007    203.0\n",
      "164024    118.0\n",
      "Name: minutes, Length: 68905, dtype: float64\n",
      "build_target_options 77000      59.0\n",
      "77001      55.0\n",
      "77002      75.0\n",
      "77003     100.0\n",
      "77004      55.0\n",
      "77005     112.0\n",
      "77006     160.0\n",
      "77007      76.0\n",
      "77008      45.0\n",
      "77009      65.0\n",
      "77010      70.0\n",
      "77011      85.0\n",
      "77012      85.0\n",
      "77013     110.0\n",
      "77014      92.0\n",
      "77015     140.0\n",
      "77016     130.0\n",
      "77017      55.0\n",
      "77018     119.0\n",
      "77019      91.0\n",
      "77020     130.0\n",
      "77021      77.0\n",
      "77022      80.0\n",
      "77023      83.0\n",
      "77025      99.0\n",
      "77026     180.0\n",
      "77027      85.0\n",
      "77028      80.0\n",
      "77029      75.0\n",
      "77030     105.0\n",
      "          ...  \n",
      "163878    131.0\n",
      "163879    152.0\n",
      "163880    187.0\n",
      "163881    213.0\n",
      "163882    168.0\n",
      "163883    115.0\n",
      "163886    154.0\n",
      "163888     87.0\n",
      "163889    122.0\n",
      "163891    213.0\n",
      "163892    203.0\n",
      "163893    163.0\n",
      "163894    173.0\n",
      "163895    175.0\n",
      "163898    144.0\n",
      "163899     92.0\n",
      "163900    134.0\n",
      "163901    164.0\n",
      "163902    132.0\n",
      "163903    184.0\n",
      "163904    296.0\n",
      "163905    217.0\n",
      "163922    146.0\n",
      "163933    150.0\n",
      "163979    127.0\n",
      "163998    178.0\n",
      "163999    254.0\n",
      "164001    233.0\n",
      "164007    203.0\n",
      "164024    118.0\n",
      "Name: minutes, Length: 68905, dtype: float64\n",
      "77000    0\n",
      "77001    0\n",
      "77002    0\n",
      "77003    1\n",
      "77004    0\n",
      "77005    1\n",
      "77006    1\n",
      "77007    0\n",
      "77008    0\n",
      "77009    0\n",
      "77010    0\n",
      "77011    0\n",
      "77012    0\n",
      "77013    1\n",
      "77014    1\n",
      "77015    1\n",
      "77016    1\n",
      "77017    0\n",
      "77018    1\n",
      "77019    1\n",
      "77020    1\n",
      "77021    0\n",
      "77022    0\n",
      "77023    0\n",
      "77025    1\n",
      "77026    1\n",
      "77027    0\n",
      "77028    0\n",
      "77029    0\n",
      "77030    1\n",
      "        ..\n",
      "77073    1\n",
      "77074    1\n",
      "77075    1\n",
      "77076    1\n",
      "77077    0\n",
      "77078    1\n",
      "77079    0\n",
      "77080    1\n",
      "77081    0\n",
      "77082    1\n",
      "77083    0\n",
      "77084    1\n",
      "77085    0\n",
      "77086    0\n",
      "77087    0\n",
      "77088    0\n",
      "77089    0\n",
      "77090    1\n",
      "77091    0\n",
      "77092    0\n",
      "77093    0\n",
      "77094    0\n",
      "77095    1\n",
      "77096    1\n",
      "77097    0\n",
      "77098    0\n",
      "77099    0\n",
      "77100    1\n",
      "77101    1\n",
      "77102    1\n",
      "Name: minutes, Length: 100, dtype: int64\n",
      "type of target <class 'pandas.core.series.Series'>\n",
      "number of dataframe data rows pre-proc: 68905\n",
      "target.shape 68905\n",
      "X.shape[0] 68905\n",
      "Y.shape[0] 68905\n",
      "yTrain.shape() (48233,)\n",
      "data_best_of        draw_size  match_num  winner_ht  winner_age  winner_rank  \\\n",
      "77000   0.225806   0.000000   0.333333    0.230329     0.020605   \n",
      "77001   0.225806   0.003145   0.377778    0.440509     0.283323   \n",
      "77002   0.225806   0.006289   0.111111    0.268399     0.133290   \n",
      "77003   0.225806   0.009434   0.444444    0.288229     0.090792   \n",
      "77004   0.225806   0.012579   0.222222    0.221527     0.029620   \n",
      "77005   0.225806   0.015723   0.377778    0.405832     0.079202   \n",
      "77006   0.225806   0.018868   0.600000    0.318558     0.121056   \n",
      "77007   0.225806   0.022013   0.266667    0.208165     0.032196   \n",
      "77008   0.225806   0.025157   0.488889    0.369141     0.068899   \n",
      "77009   0.225806   0.028302   0.444444    0.282927     0.092724   \n",
      "77010   0.225806   0.031447   0.488889    0.448356     0.094656   \n",
      "\n",
      "       winner_rank_points  loser_ht  loser_age  loser_rank  loser_rank_points  \\\n",
      "77000            0.046315  0.375000   0.492111    0.114286           0.008968   \n",
      "77001            0.002065  0.479167   0.354854    0.312571           0.001239   \n",
      "77002            0.008378  0.312500   0.626367    0.126857           0.006962   \n",
      "77003            0.014632  0.625000   0.275772    0.068571           0.018526   \n",
      "77004            0.037229  0.312500   0.171523    0.146286           0.005369   \n",
      "77005            0.017641  0.270833   0.287194    0.080000           0.014868   \n",
      "77006            0.009558  0.479167   0.191269    0.079429           0.015222   \n",
      "77007            0.034987  0.520833   0.301229    0.091429           0.012095   \n",
      "77008            0.020532  0.270833   0.412932    0.112000           0.009263   \n",
      "77009            0.013983  0.520833   0.285645    0.090286           0.012626   \n",
      "77010            0.013806  0.416667   0.196206    0.081714           0.014337   \n",
      "\n",
      "           ...       surface_Carpet  surface_Clay  surface_Grass  \\\n",
      "77000      ...                  0.0           1.0            0.0   \n",
      "77001      ...                  0.0           1.0            0.0   \n",
      "77002      ...                  0.0           1.0            0.0   \n",
      "77003      ...                  0.0           1.0            0.0   \n",
      "77004      ...                  0.0           1.0            0.0   \n",
      "77005      ...                  0.0           1.0            0.0   \n",
      "77006      ...                  0.0           1.0            0.0   \n",
      "77007      ...                  0.0           1.0            0.0   \n",
      "77008      ...                  0.0           1.0            0.0   \n",
      "77009      ...                  0.0           1.0            0.0   \n",
      "77010      ...                  0.0           1.0            0.0   \n",
      "\n",
      "       surface_Hard  winner_hand_L  winner_hand_R  winner_hand_U  \\\n",
      "77000           0.0            0.0            1.0            0.0   \n",
      "77001           0.0            0.0            1.0            0.0   \n",
      "77002           0.0            0.0            1.0            0.0   \n",
      "77003           0.0            0.0            1.0            0.0   \n",
      "77004           0.0            1.0            0.0            0.0   \n",
      "77005           0.0            0.0            1.0            0.0   \n",
      "77006           0.0            0.0            1.0            0.0   \n",
      "77007           0.0            0.0            1.0            0.0   \n",
      "77008           0.0            1.0            0.0            0.0   \n",
      "77009           0.0            1.0            0.0            0.0   \n",
      "77010           0.0            1.0            0.0            0.0   \n",
      "\n",
      "       loser_hand_L  loser_hand_R  loser_hand_U  \n",
      "77000           0.0           1.0           0.0  \n",
      "77001           0.0           1.0           0.0  \n",
      "77002           0.0           1.0           0.0  \n",
      "77003           1.0           0.0           0.0  \n",
      "77004           0.0           1.0           0.0  \n",
      "77005           0.0           1.0           0.0  \n",
      "77006           0.0           1.0           0.0  \n",
      "77007           0.0           1.0           0.0  \n",
      "77008           0.0           1.0           0.0  \n",
      "77009           0.0           1.0           0.0  \n",
      "77010           0.0           1.0           0.0  \n",
      "\n",
      "[11 rows x 21 columns]\n",
      "target_best_of 77000    0\n",
      "77001    0\n",
      "77002    0\n",
      "77003    1\n",
      "77004    0\n",
      "77005    1\n",
      "77006    1\n",
      "77007    0\n",
      "77008    0\n",
      "77009    0\n",
      "Name: minutes, dtype: int64\n",
      "156842    1\n",
      "116682    0\n",
      "138641    0\n",
      "155994    1\n",
      "140775    1\n",
      "122764    0\n",
      "92620     1\n",
      "96645     1\n",
      "77081     0\n",
      "102913    1\n",
      "134351    0\n",
      "Name: minutes, dtype: int64\n",
      "        draw_size  match_num  winner_ht  winner_age  winner_rank  \\\n",
      "156842   1.000000   0.216981   0.555556    0.446766     0.026401   \n",
      "116682   0.225806   0.018868   0.488889    0.284942     0.068255   \n",
      "138641   0.225806   0.025157   0.488889    0.227890     0.004507   \n",
      "155994   0.741935   0.113208   0.733333    0.284942     0.006439   \n",
      "140775   0.225806   0.000000   0.444444    0.329480     0.014810   \n",
      "122764   0.225806   0.066038   0.488889    0.290032     0.015454   \n",
      "92620    0.225806   0.069182   0.555556    0.541145     0.014166   \n",
      "96645    0.225806   0.044025   0.600000    0.388123     0.066967   \n",
      "77081    0.225806   0.059748   0.488889    0.689183     0.040567   \n",
      "102913   0.419355   0.084906   0.600000    0.295652     0.003220   \n",
      "\n",
      "        winner_rank_points  loser_ht  loser_age  loser_rank  \\\n",
      "156842            0.059827  0.708333   0.471203    0.032571   \n",
      "116682            0.023541  0.583333   0.432291    0.028000   \n",
      "138641            0.111157  0.520833   0.342174    0.020000   \n",
      "155994            0.146557  0.583333   0.520279    0.023429   \n",
      "140775            0.104667  0.625000   0.115381    0.206857   \n",
      "122764            0.075167  0.479167   0.412254    0.075429   \n",
      "92620             0.069739  0.416667   0.383022    0.014286   \n",
      "96645             0.026786  0.625000   0.339270    0.049714   \n",
      "77081             0.029854  0.520833   0.474785    0.052000   \n",
      "102913            0.140539  0.583333   0.319621    0.016571   \n",
      "\n",
      "        loser_rank_points      ...       surface_Carpet  surface_Clay  \\\n",
      "156842           0.048734      ...                  0.0           0.0   \n",
      "116682           0.043896      ...                  0.0           0.0   \n",
      "138641           0.054516      ...                  0.0           0.0   \n",
      "155994           0.059119      ...                  0.0           0.0   \n",
      "140775           0.007729      ...                  0.0           1.0   \n",
      "122764           0.016520      ...                  0.0           1.0   \n",
      "92620            0.067615      ...                  0.0           0.0   \n",
      "96645            0.031034      ...                  0.0           0.0   \n",
      "77081            0.023836      ...                  1.0           0.0   \n",
      "102913           0.075049      ...                  0.0           0.0   \n",
      "\n",
      "        surface_Grass  surface_Hard  winner_hand_L  winner_hand_R  \\\n",
      "156842            1.0           0.0            0.0            1.0   \n",
      "116682            1.0           0.0            0.0            1.0   \n",
      "138641            0.0           1.0            0.0            1.0   \n",
      "155994            0.0           1.0            0.0            1.0   \n",
      "140775            0.0           0.0            0.0            1.0   \n",
      "122764            0.0           0.0            0.0            1.0   \n",
      "92620             0.0           1.0            0.0            1.0   \n",
      "96645             0.0           1.0            1.0            0.0   \n",
      "77081             0.0           0.0            0.0            1.0   \n",
      "102913            0.0           1.0            0.0            1.0   \n",
      "\n",
      "        winner_hand_U  loser_hand_L  loser_hand_R  loser_hand_U  \n",
      "156842            0.0           0.0           1.0           0.0  \n",
      "116682            0.0           1.0           0.0           0.0  \n",
      "138641            0.0           0.0           1.0           0.0  \n",
      "155994            0.0           0.0           1.0           0.0  \n",
      "140775            0.0           1.0           0.0           0.0  \n",
      "122764            0.0           0.0           1.0           0.0  \n",
      "92620             0.0           0.0           1.0           0.0  \n",
      "96645             0.0           1.0           0.0           0.0  \n",
      "77081             0.0           0.0           1.0           0.0  \n",
      "102913            0.0           0.0           1.0           0.0  \n",
      "\n",
      "[10 rows x 21 columns]\n",
      "yTest 131916    0\n",
      "89610     0\n",
      "99150     0\n",
      "160967    1\n",
      "137119    1\n",
      "84040     1\n",
      "107490    1\n",
      "140870    1\n",
      "149376    1\n",
      "106412    0\n",
      "94701     0\n",
      "135523    1\n",
      "108087    1\n",
      "111052    1\n",
      "143712    1\n",
      "156028    1\n",
      "137956    1\n",
      "163110    0\n",
      "116524    1\n",
      "155074    1\n",
      "107149    1\n",
      "78646     0\n",
      "95246     0\n",
      "103738    0\n",
      "112039    0\n",
      "82154     0\n",
      "97153     1\n",
      "128265    0\n",
      "106355    1\n",
      "103043    1\n",
      "         ..\n",
      "116450    1\n",
      "114258    0\n",
      "81211     0\n",
      "98626     0\n",
      "110739    1\n",
      "113012    0\n",
      "143393    1\n",
      "126167    1\n",
      "121794    0\n",
      "116630    0\n",
      "156284    0\n",
      "118039    0\n",
      "133590    0\n",
      "83879     1\n",
      "132004    1\n",
      "154099    1\n",
      "144882    1\n",
      "149616    1\n",
      "144605    1\n",
      "132422    1\n",
      "135699    0\n",
      "86530     0\n",
      "104932    1\n",
      "137317    0\n",
      "125536    1\n",
      "109400    1\n",
      "156360    0\n",
      "113845    1\n",
      "111300    0\n",
      "154407    1\n",
      "Name: minutes, Length: 20672, dtype: int64\n",
      "data         draw_size  match_num  winner_ht  winner_age  winner_rank  \\\n",
      "77000    0.225806   0.000000   0.333333    0.230329     0.020605   \n",
      "77001    0.225806   0.003145   0.377778    0.440509     0.283323   \n",
      "77002    0.225806   0.006289   0.111111    0.268399     0.133290   \n",
      "77003    0.225806   0.009434   0.444444    0.288229     0.090792   \n",
      "77004    0.225806   0.012579   0.222222    0.221527     0.029620   \n",
      "77005    0.225806   0.015723   0.377778    0.405832     0.079202   \n",
      "77006    0.225806   0.018868   0.600000    0.318558     0.121056   \n",
      "77007    0.225806   0.022013   0.266667    0.208165     0.032196   \n",
      "77008    0.225806   0.025157   0.488889    0.369141     0.068899   \n",
      "77009    0.225806   0.028302   0.444444    0.282927     0.092724   \n",
      "77010    0.225806   0.031447   0.488889    0.448356     0.094656   \n",
      "77011    0.225806   0.034591   0.600000    0.172110     0.027044   \n",
      "77012    0.225806   0.037736   0.600000    0.212195     0.073406   \n",
      "77013    0.225806   0.040881   0.377778    0.399258     0.110753   \n",
      "77014    0.225806   0.044025   0.444444    0.214528     0.115261   \n",
      "77015    0.225806   0.047170   0.266667    0.429480     0.018674   \n",
      "77016    0.225806   0.050314   0.333333    0.230329     0.020605   \n",
      "77017    0.225806   0.053459   0.444444    0.288229     0.090792   \n",
      "77018    0.225806   0.056604   0.222222    0.221527     0.029620   \n",
      "77019    0.225806   0.059748   0.266667    0.208165     0.032196   \n",
      "77020    0.225806   0.062893   0.488889    0.369141     0.068899   \n",
      "77021    0.225806   0.066038   0.600000    0.172110     0.027044   \n",
      "77022    0.225806   0.069182   0.377778    0.399258     0.110753   \n",
      "77023    0.225806   0.072327   0.444444    0.214528     0.115261   \n",
      "77025    0.225806   0.078616   0.266667    0.208165     0.032196   \n",
      "77026    0.225806   0.081761   0.488889    0.369141     0.068899   \n",
      "77027    0.225806   0.084906   0.444444    0.214528     0.115261   \n",
      "77028    0.225806   0.088050   0.333333    0.230329     0.020605   \n",
      "77029    0.225806   0.091195   0.444444    0.214528     0.115261   \n",
      "77030    0.225806   0.094340   0.333333    0.230329     0.020605   \n",
      "...           ...        ...        ...         ...          ...   \n",
      "163878   1.000000   0.622642   0.333333    0.434783     0.002576   \n",
      "163879   1.000000   0.625786   0.444444    0.618982     0.001932   \n",
      "163880   1.000000   0.628931   0.600000    0.661506     0.056665   \n",
      "163881   1.000000   0.632075   0.555556    0.616861     0.007083   \n",
      "163882   1.000000   0.635220   0.266667    0.419406     0.032196   \n",
      "163883   1.000000   0.638365   0.666667    0.563627     0.003220   \n",
      "163886   1.000000   0.647799   0.733333    0.396288     0.001288   \n",
      "163888   1.000000   0.654088   0.000000    0.398409     0.006439   \n",
      "163889   1.000000   0.657233   0.555556    0.381442     0.009015   \n",
      "163891   1.000000   0.663522   0.600000    0.525981     0.031552   \n",
      "163892   1.000000   0.666667   0.488889    0.759809     0.010303   \n",
      "163893   1.000000   0.669811   0.444444    0.618982     0.001932   \n",
      "163894   1.000000   0.672956   0.555556    0.616861     0.007083   \n",
      "163895   1.000000   0.676101   0.488889    0.573171     0.005151   \n",
      "163898   1.000000   0.685535   0.555556    0.381442     0.009015   \n",
      "163899   1.000000   0.688679   0.488889    0.759809     0.010303   \n",
      "163900   1.000000   0.691824   0.444444    0.618982     0.001932   \n",
      "163901   1.000000   0.694969   0.488889    0.573171     0.005151   \n",
      "163902   1.000000   0.698113   0.555556    0.381442     0.009015   \n",
      "163903   1.000000   0.701258   0.488889    0.759809     0.010303   \n",
      "163904   1.000000   0.704403   0.488889    0.573171     0.005151   \n",
      "163905   1.000000   0.707547   0.488889    0.759809     0.010303   \n",
      "163922   0.000000   0.003145   0.333333    0.401273     0.048294   \n",
      "163933   0.000000   0.000000   0.600000    0.454401     0.022537   \n",
      "163979   0.000000   0.009434   0.600000    0.681866     0.262073   \n",
      "163998   0.000000   0.003145   0.600000    0.662990     0.043142   \n",
      "163999   0.000000   0.009434   0.444444    0.703606     0.051513   \n",
      "164001   0.000000   0.000000   0.333333    0.660764     0.036703   \n",
      "164007   0.000000   0.009434   0.666667    0.417603     0.084997   \n",
      "164024   0.000000   0.000000   0.488889    0.330223     0.012234   \n",
      "\n",
      "        winner_rank_points  loser_ht  loser_age  loser_rank  \\\n",
      "77000             0.046315  0.375000   0.492111    0.114286   \n",
      "77001             0.002065  0.479167   0.354854    0.312571   \n",
      "77002             0.008378  0.312500   0.626367    0.126857   \n",
      "77003             0.014632  0.625000   0.275772    0.068571   \n",
      "77004             0.037229  0.312500   0.171523    0.146286   \n",
      "77005             0.017641  0.270833   0.287194    0.080000   \n",
      "77006             0.009558  0.479167   0.191269    0.079429   \n",
      "77007             0.034987  0.520833   0.301229    0.091429   \n",
      "77008             0.020532  0.270833   0.412932    0.112000   \n",
      "77009             0.013983  0.520833   0.285645    0.090286   \n",
      "77010             0.013806  0.416667   0.196206    0.081714   \n",
      "77011             0.039825  0.270833   0.420869    0.622286   \n",
      "77012             0.019765  0.375000   0.468299    0.108000   \n",
      "77013             0.010502  0.520833   0.255154    0.224000   \n",
      "77014             0.010207  0.479167   0.315555    0.198286   \n",
      "77015             0.049560  0.208333   0.532669    0.076000   \n",
      "77016             0.046315  0.416667   0.411964    0.251429   \n",
      "77017             0.014632  0.166667   0.254864    0.118286   \n",
      "77018             0.037229  0.416667   0.380312    0.070286   \n",
      "77019             0.034987  0.625000   0.300649    0.107429   \n",
      "77020             0.020532  0.479167   0.268125    0.082286   \n",
      "77021             0.039825  0.520833   0.419127    0.084000   \n",
      "77022             0.010502  0.625000   0.203562    0.065143   \n",
      "77023             0.010207  0.312500   0.401897    0.016571   \n",
      "77025             0.034987  0.270833   0.212080    0.026286   \n",
      "77026             0.020532  0.625000   0.166973    0.024000   \n",
      "77027             0.010207  0.416667   0.374310    0.098286   \n",
      "77028             0.046315  0.312500   0.199884    0.028571   \n",
      "77029             0.010207  0.520833   0.346820    0.061143   \n",
      "77030             0.046315  0.479167   0.205692    0.102286   \n",
      "...                    ...       ...        ...         ...   \n",
      "163878            0.295534  0.520833   0.482915    0.068571   \n",
      "163879            0.304089  0.687500   0.543994    0.019429   \n",
      "163880            0.037406  0.375000   0.611654    0.040000   \n",
      "163881            0.147737  0.520833   0.309941    0.010857   \n",
      "163882            0.052215  0.687500   0.307327    0.014857   \n",
      "163883            0.213818  0.375000   0.626077    0.018286   \n",
      "163886            0.312054  0.479167   0.583680    0.013714   \n",
      "163888            0.162192  1.000000   0.789759    0.011429   \n",
      "163889            0.125907  0.520833   0.531604    0.009714   \n",
      "163891            0.052687  0.625000   0.499564    0.000000   \n",
      "163892            0.116762  0.375000   0.406737    0.002286   \n",
      "163893            0.304089  0.625000   0.613687    0.050286   \n",
      "163894            0.147737  0.312500   0.392702    0.028571   \n",
      "163895            0.188448  0.687500   0.524344    0.002857   \n",
      "163898            0.125907  0.583333   0.523763    0.066286   \n",
      "163899            0.116762  0.625000   0.489982    0.028000   \n",
      "163900            0.304089  0.583333   0.572936    0.006286   \n",
      "163901            0.188448  0.750000   0.371600    0.001143   \n",
      "163902            0.125907  0.062500   0.373536    0.005714   \n",
      "163903            0.116762  0.479167   0.574872    0.001714   \n",
      "163904            0.188448  0.583333   0.358049    0.008000   \n",
      "163905            0.116762  0.520833   0.533056    0.004571   \n",
      "163922            0.040356  0.312500   0.575549    0.042286   \n",
      "163933            0.072512  0.416667   0.452425    0.161714   \n",
      "163979            0.006077  0.520833   0.465105    0.389143   \n",
      "163998            0.042716  0.479167   0.652115    0.045714   \n",
      "163999            0.039353  0.479167   0.692285    0.024000   \n",
      "164001            0.046374  0.375000   0.627432    0.016000   \n",
      "164007            0.025783  0.312500   0.394057    0.025143   \n",
      "164024            0.109387  0.520833   0.701578    0.082857   \n",
      "\n",
      "        loser_rank_points      ...       surface_Carpet  surface_Clay  \\\n",
      "77000            0.008968      ...                  0.0           1.0   \n",
      "77001            0.001239      ...                  0.0           1.0   \n",
      "77002            0.006962      ...                  0.0           1.0   \n",
      "77003            0.018526      ...                  0.0           1.0   \n",
      "77004            0.005369      ...                  0.0           1.0   \n",
      "77005            0.014868      ...                  0.0           1.0   \n",
      "77006            0.015222      ...                  0.0           1.0   \n",
      "77007            0.012095      ...                  0.0           1.0   \n",
      "77008            0.009263      ...                  0.0           1.0   \n",
      "77009            0.012626      ...                  0.0           1.0   \n",
      "77010            0.014337      ...                  0.0           1.0   \n",
      "77011            0.000000      ...                  0.0           1.0   \n",
      "77012            0.009558      ...                  0.0           1.0   \n",
      "77013            0.002714      ...                  0.0           1.0   \n",
      "77014            0.003304      ...                  0.0           1.0   \n",
      "77015            0.016402      ...                  0.0           1.0   \n",
      "77016            0.002065      ...                  0.0           1.0   \n",
      "77017            0.008378      ...                  0.0           1.0   \n",
      "77018            0.017641      ...                  0.0           1.0   \n",
      "77019            0.009558      ...                  0.0           1.0   \n",
      "77020            0.013983      ...                  0.0           1.0   \n",
      "77021            0.013806      ...                  0.0           1.0   \n",
      "77022            0.019765      ...                  0.0           1.0   \n",
      "77023            0.049560      ...                  0.0           1.0   \n",
      "77025            0.037229      ...                  0.0           1.0   \n",
      "77026            0.039825      ...                  0.0           1.0   \n",
      "77027            0.010502      ...                  0.0           1.0   \n",
      "77028            0.034987      ...                  0.0           1.0   \n",
      "77029            0.020532      ...                  0.0           1.0   \n",
      "77030            0.010207      ...                  0.0           1.0   \n",
      "...                   ...      ...                  ...           ...   \n",
      "163878           0.028615      ...                  0.0           0.0   \n",
      "163879           0.072217      ...                  0.0           0.0   \n",
      "163880           0.041654      ...                  0.0           0.0   \n",
      "163881           0.106732      ...                  0.0           0.0   \n",
      "163882           0.083722      ...                  0.0           0.0   \n",
      "163883           0.078117      ...                  0.0           0.0   \n",
      "163886           0.093457      ...                  0.0           0.0   \n",
      "163888           0.105847      ...                  0.0           0.0   \n",
      "163889           0.111157      ...                  0.0           0.0   \n",
      "163891           0.740988      ...                  0.0           0.0   \n",
      "163892           0.295534      ...                  0.0           0.0   \n",
      "163893           0.037406      ...                  0.0           0.0   \n",
      "163894           0.052215      ...                  0.0           0.0   \n",
      "163895           0.213818      ...                  0.0           0.0   \n",
      "163898           0.029323      ...                  0.0           0.0   \n",
      "163899           0.052687      ...                  0.0           0.0   \n",
      "163900           0.147737      ...                  0.0           0.0   \n",
      "163901           0.312054      ...                  0.0           0.0   \n",
      "163902           0.162192      ...                  0.0           0.0   \n",
      "163903           0.304089      ...                  0.0           0.0   \n",
      "163904           0.125907      ...                  0.0           0.0   \n",
      "163905           0.188448      ...                  0.0           0.0   \n",
      "163922           0.040415      ...                  0.0           1.0   \n",
      "163933           0.010502      ...                  0.0           0.0   \n",
      "163979           0.002065      ...                  1.0           0.0   \n",
      "163998           0.039353      ...                  0.0           1.0   \n",
      "163999           0.061420      ...                  0.0           1.0   \n",
      "164001           0.082837      ...                  0.0           0.0   \n",
      "164007           0.060771      ...                  0.0           0.0   \n",
      "164024           0.024367      ...                  0.0           0.0   \n",
      "\n",
      "        surface_Grass  surface_Hard  winner_hand_L  winner_hand_R  \\\n",
      "77000             0.0           0.0            0.0            1.0   \n",
      "77001             0.0           0.0            0.0            1.0   \n",
      "77002             0.0           0.0            0.0            1.0   \n",
      "77003             0.0           0.0            0.0            1.0   \n",
      "77004             0.0           0.0            1.0            0.0   \n",
      "77005             0.0           0.0            0.0            1.0   \n",
      "77006             0.0           0.0            0.0            1.0   \n",
      "77007             0.0           0.0            0.0            1.0   \n",
      "77008             0.0           0.0            1.0            0.0   \n",
      "77009             0.0           0.0            1.0            0.0   \n",
      "77010             0.0           0.0            1.0            0.0   \n",
      "77011             0.0           0.0            0.0            1.0   \n",
      "77012             0.0           0.0            1.0            0.0   \n",
      "77013             0.0           0.0            0.0            1.0   \n",
      "77014             0.0           0.0            0.0            1.0   \n",
      "77015             0.0           0.0            0.0            1.0   \n",
      "77016             0.0           0.0            0.0            1.0   \n",
      "77017             0.0           0.0            0.0            1.0   \n",
      "77018             0.0           0.0            1.0            0.0   \n",
      "77019             0.0           0.0            0.0            1.0   \n",
      "77020             0.0           0.0            1.0            0.0   \n",
      "77021             0.0           0.0            0.0            1.0   \n",
      "77022             0.0           0.0            0.0            1.0   \n",
      "77023             0.0           0.0            0.0            1.0   \n",
      "77025             0.0           0.0            0.0            1.0   \n",
      "77026             0.0           0.0            1.0            0.0   \n",
      "77027             0.0           0.0            0.0            1.0   \n",
      "77028             0.0           0.0            0.0            1.0   \n",
      "77029             0.0           0.0            0.0            1.0   \n",
      "77030             0.0           0.0            0.0            1.0   \n",
      "...               ...           ...            ...            ...   \n",
      "163878            0.0           1.0            0.0            1.0   \n",
      "163879            0.0           1.0            0.0            1.0   \n",
      "163880            0.0           1.0            0.0            1.0   \n",
      "163881            0.0           1.0            0.0            1.0   \n",
      "163882            0.0           1.0            0.0            1.0   \n",
      "163883            0.0           1.0            0.0            1.0   \n",
      "163886            0.0           1.0            0.0            1.0   \n",
      "163888            0.0           1.0            0.0            1.0   \n",
      "163889            0.0           1.0            0.0            1.0   \n",
      "163891            0.0           1.0            1.0            0.0   \n",
      "163892            0.0           1.0            0.0            1.0   \n",
      "163893            0.0           1.0            0.0            1.0   \n",
      "163894            0.0           1.0            0.0            1.0   \n",
      "163895            0.0           1.0            1.0            0.0   \n",
      "163898            0.0           1.0            0.0            1.0   \n",
      "163899            0.0           1.0            0.0            1.0   \n",
      "163900            0.0           1.0            0.0            1.0   \n",
      "163901            0.0           1.0            1.0            0.0   \n",
      "163902            0.0           1.0            0.0            1.0   \n",
      "163903            0.0           1.0            0.0            1.0   \n",
      "163904            0.0           1.0            1.0            0.0   \n",
      "163905            0.0           1.0            0.0            1.0   \n",
      "163922            0.0           0.0            0.0            1.0   \n",
      "163933            0.0           1.0            1.0            0.0   \n",
      "163979            0.0           0.0            0.0            1.0   \n",
      "163998            0.0           0.0            0.0            1.0   \n",
      "163999            0.0           0.0            0.0            1.0   \n",
      "164001            0.0           1.0            0.0            1.0   \n",
      "164007            0.0           1.0            0.0            1.0   \n",
      "164024            0.0           1.0            0.0            1.0   \n",
      "\n",
      "        winner_hand_U  loser_hand_L  loser_hand_R  loser_hand_U  \n",
      "77000             0.0           0.0           1.0           0.0  \n",
      "77001             0.0           0.0           1.0           0.0  \n",
      "77002             0.0           0.0           1.0           0.0  \n",
      "77003             0.0           1.0           0.0           0.0  \n",
      "77004             0.0           0.0           1.0           0.0  \n",
      "77005             0.0           0.0           1.0           0.0  \n",
      "77006             0.0           0.0           1.0           0.0  \n",
      "77007             0.0           0.0           1.0           0.0  \n",
      "77008             0.0           0.0           1.0           0.0  \n",
      "77009             0.0           0.0           1.0           0.0  \n",
      "77010             0.0           0.0           1.0           0.0  \n",
      "77011             0.0           0.0           1.0           0.0  \n",
      "77012             0.0           1.0           0.0           0.0  \n",
      "77013             0.0           0.0           1.0           0.0  \n",
      "77014             0.0           0.0           1.0           0.0  \n",
      "77015             0.0           0.0           1.0           0.0  \n",
      "77016             0.0           0.0           1.0           0.0  \n",
      "77017             0.0           0.0           1.0           0.0  \n",
      "77018             0.0           0.0           1.0           0.0  \n",
      "77019             0.0           0.0           1.0           0.0  \n",
      "77020             0.0           1.0           0.0           0.0  \n",
      "77021             0.0           1.0           0.0           0.0  \n",
      "77022             0.0           1.0           0.0           0.0  \n",
      "77023             0.0           0.0           1.0           0.0  \n",
      "77025             0.0           1.0           0.0           0.0  \n",
      "77026             0.0           0.0           1.0           0.0  \n",
      "77027             0.0           0.0           1.0           0.0  \n",
      "77028             0.0           0.0           1.0           0.0  \n",
      "77029             0.0           1.0           0.0           0.0  \n",
      "77030             0.0           0.0           1.0           0.0  \n",
      "...               ...           ...           ...           ...  \n",
      "163878            0.0           0.0           1.0           0.0  \n",
      "163879            0.0           0.0           1.0           0.0  \n",
      "163880            0.0           0.0           1.0           0.0  \n",
      "163881            0.0           0.0           1.0           0.0  \n",
      "163882            0.0           0.0           1.0           0.0  \n",
      "163883            0.0           0.0           1.0           0.0  \n",
      "163886            0.0           0.0           1.0           0.0  \n",
      "163888            0.0           0.0           1.0           0.0  \n",
      "163889            0.0           0.0           1.0           0.0  \n",
      "163891            0.0           0.0           1.0           0.0  \n",
      "163892            0.0           0.0           1.0           0.0  \n",
      "163893            0.0           0.0           1.0           0.0  \n",
      "163894            0.0           0.0           1.0           0.0  \n",
      "163895            0.0           0.0           1.0           0.0  \n",
      "163898            0.0           0.0           1.0           0.0  \n",
      "163899            0.0           1.0           0.0           0.0  \n",
      "163900            0.0           0.0           1.0           0.0  \n",
      "163901            0.0           0.0           1.0           0.0  \n",
      "163902            0.0           0.0           1.0           0.0  \n",
      "163903            0.0           0.0           1.0           0.0  \n",
      "163904            0.0           0.0           1.0           0.0  \n",
      "163905            0.0           1.0           0.0           0.0  \n",
      "163922            0.0           0.0           1.0           0.0  \n",
      "163933            0.0           0.0           1.0           0.0  \n",
      "163979            0.0           0.0           1.0           0.0  \n",
      "163998            0.0           0.0           1.0           0.0  \n",
      "163999            0.0           0.0           1.0           0.0  \n",
      "164001            0.0           0.0           1.0           0.0  \n",
      "164007            0.0           0.0           1.0           0.0  \n",
      "164024            0.0           0.0           1.0           0.0  \n",
      "\n",
      "[68905 rows x 21 columns]\n",
      "target 77000     0\n",
      "77001     0\n",
      "77002     0\n",
      "77003     1\n",
      "77004     0\n",
      "77005     1\n",
      "77006     1\n",
      "77007     0\n",
      "77008     0\n",
      "77009     0\n",
      "77010     0\n",
      "77011     0\n",
      "77012     0\n",
      "77013     1\n",
      "77014     1\n",
      "77015     1\n",
      "77016     1\n",
      "77017     0\n",
      "77018     1\n",
      "77019     1\n",
      "77020     1\n",
      "77021     0\n",
      "77022     0\n",
      "77023     0\n",
      "77025     1\n",
      "77026     1\n",
      "77027     0\n",
      "77028     0\n",
      "77029     0\n",
      "77030     1\n",
      "         ..\n",
      "163878    1\n",
      "163879    1\n",
      "163880    1\n",
      "163881    1\n",
      "163882    1\n",
      "163883    1\n",
      "163886    1\n",
      "163888    0\n",
      "163889    1\n",
      "163891    1\n",
      "163892    1\n",
      "163893    1\n",
      "163894    1\n",
      "163895    1\n",
      "163898    1\n",
      "163899    1\n",
      "163900    1\n",
      "163901    1\n",
      "163902    1\n",
      "163903    1\n",
      "163904    1\n",
      "163905    1\n",
      "163922    1\n",
      "163933    1\n",
      "163979    1\n",
      "163998    1\n",
      "163999    1\n",
      "164001    1\n",
      "164007    1\n",
      "164024    1\n",
      "Name: minutes, Length: 68905, dtype: int64\n",
      "yTrain.shape() (48233,)\n",
      "XTrain.shape() (48233, 21)\n",
      "XTrain [[1.         0.21698113 0.55555556 0.44676564 0.02640052 0.05982654\n",
      "  0.70833333 0.47120317 0.03257143 0.04873444 1.         0.\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.01886792 0.48888889 0.28494168 0.06825499 0.02354121\n",
      "  0.58333333 0.43229116 0.028      0.0438964  0.         0.\n",
      "  0.         1.         0.         0.         1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [0.22580645 0.02515723 0.48888889 0.22788971 0.00450741 0.111157\n",
      "  0.52083333 0.34217404 0.02       0.05451649 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.74193548 0.11320755 0.73333333 0.28494168 0.00643915 0.14655732\n",
      "  0.58333333 0.52027877 0.02342857 0.05911853 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.         0.44444444 0.32948038 0.01481005 0.10466694\n",
      "  0.625      0.11538089 0.20685714 0.00772907 0.         0.\n",
      "  1.         0.         0.         0.         1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [0.22580645 0.06603774 0.48888889 0.29003181 0.01545396 0.07516668\n",
      "  0.47916667 0.41225438 0.07542857 0.01652015 0.         0.\n",
      "  1.         0.         0.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.06918239 0.55555556 0.54114528 0.01416613 0.06973863\n",
      "  0.41666667 0.38302197 0.01428571 0.06761461 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.04402516 0.6        0.38812301 0.06696716 0.02678624\n",
      "  0.625      0.33927016 0.04971429 0.03103428 0.         0.\n",
      "  0.         0.         1.         1.         0.         0.\n",
      "  1.         0.         0.        ]\n",
      " [0.22580645 0.05974843 0.48888889 0.68918346 0.04056665 0.02985427\n",
      "  0.52083333 0.47478463 0.052      0.02383621 0.         1.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.41935484 0.08490566 0.6        0.29565217 0.00321958 0.14053926\n",
      "  0.58333333 0.31962056 0.01657143 0.07504868 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]]\n",
      "yTrain [1 0 0 1 1 0 1 1 0 1]\n",
      "XTest [[0.22580645 0.02830189 0.44444444 0.72513256 0.03090792 0.04525341\n",
      "  0.75       0.45532862 0.196      0.00590005 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.35483871 0.11006289 0.6        0.42979852 0.00321958 0.14938934\n",
      "  0.58333333 0.46587939 0.01828571 0.05457549 0.         1.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.48387097 0.11320755 0.6        0.2457052  0.00515132 0.12873916\n",
      "  0.58333333 0.51911722 0.01714286 0.06141955 0.         0.\n",
      "  1.         0.         0.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.90566038 0.6        0.41580064 0.02768835 0.05422149\n",
      "  0.75       0.52957119 0.02571429 0.05138946 0.         0.\n",
      "  0.         0.         1.         1.         0.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.03773585 0.33333333 0.32545069 0.01931745 0.0554015\n",
      "  0.27083333 0.4999516  0.05714286 0.02507523 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.02201258 0.44444444 0.29756098 0.01609788 0.06254056\n",
      "  0.75       0.22340529 0.04857143 0.02525223 0.         0.\n",
      "  1.         0.         0.         1.         0.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.41935484 0.06603774 0.66666667 0.13319194 0.01802962 0.06908962\n",
      "  0.625      0.44342271 0.03657143 0.04206738 0.         0.\n",
      "  1.         0.         0.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.22580645 0.01886792 0.48888889 0.40116649 0.01802962 0.11351702\n",
      "  0.58333333 0.28961378 0.03371429 0.07050563 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.19354839 0.06918239 0.66666667 0.48504772 0.07469414 0.02832025\n",
      "  0.58333333 0.34101249 0.036      0.04371939 0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]\n",
      " [0.74193548 0.05031447 0.44444444 0.16924708 0.03283967 0.05085846\n",
      "  0.625      0.40344594 0.04742857 0.0335713  0.         0.\n",
      "  0.         0.         1.         0.         1.         0.\n",
      "  0.         1.         0.        ]]\n",
      "yTest [0 0 0 ... 1 0 1]\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "type(XTrain) <class 'numpy.ndarray'>\n",
      "type(yTrain) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:601: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:602: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:603: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:605: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:606: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP best_params_ {'max_depth': 8, 'n_estimators': 50}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e34d9582eb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;31m#--- RFC model: it works about with minutes ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0mRFCmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m \u001b[0mRFC_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRFC_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRFC_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFCmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_forest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m '''\n\u001b[1;32m    615\u001b[0m \u001b[0mencouraging\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnormalize_numerical_variables\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre_proc_lib_12dec\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Linear Regression Models for regression and classification problems\n",
    "\n",
    "Move Tree part to aoter notbook\n",
    "\n",
    "OVERALL SOFTWARE ARCHITECTURE:\n",
    "0- use a yaml config file for list of features to be excluded wr dataset\n",
    "1- pre_proc_lib\n",
    "2- ML_linear_models\n",
    "3- ML_treebased_models\n",
    "4- DL_models\n",
    "5- ML_analysis_operations_pipeline\n",
    "\n",
    "TOY DATASETS\n",
    "https://scikit-learn.org/stable/datasets/index.html\n",
    "\n",
    "MACHINE LEARNING\n",
    "https://scikit-learn.org/stable/supervised_learning.html\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "DIFFICULTIES\n",
    "1- Missing values\n",
    "2- Imbalanced dataset\n",
    "'''\n",
    "class MLmodels():\n",
    "    '''\n",
    "    Top base model for ML subseq\n",
    "    '''\n",
    "    def __init__(self, XTrain, XTest, yTrain, yTest):\n",
    "        '''\n",
    "        X,yTrain and X,yTest come from pre_proc_lib applied on dataset\n",
    "        '''\n",
    "        self.XTrain = XTrain\n",
    "        self.XTest = XTest\n",
    "        self.yTrain = yTrain\n",
    "        self.yTest = yTest\n",
    "\n",
    "#/////////////////////////////////////////\n",
    "class TreeBasedModels(MLmodels):\n",
    "    '''\n",
    "    Purpose: combine pre_proc_lib and tree_based_models_lib:\n",
    "    '''\n",
    "    NUMBER_ESTIMATORS = 40\n",
    "    LEARN_RATE = 0.01\n",
    "    SUB_SAMPLE = 0.8\n",
    "    MAX_DEPTH = 4\n",
    "    LOSS_FUNCTION = 'ls'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_model = 'tree-based-models'\n",
    "        \n",
    "        \n",
    "class GradientBoostedRegressor(TreeBasedModels):\n",
    "    '''\n",
    "    class to manage gradient tree boosted operations\n",
    "    '''\n",
    "    def __init__(self, xTrain, xTest, yTrain, yTest):\n",
    "        self.GBMModel = None\n",
    "        self.GBMModelFit = None\n",
    "        self.mse_list = []\n",
    "        self.normalFeatureImportances = None\n",
    "        self.target_predictions = None\n",
    "        print('GradientBoostReg yTrain: %s'%str(self.yTrain))\n",
    "    \n",
    "    def gradient_boosting_regressor(self):\n",
    "        '''\n",
    "        Model digest:       \n",
    "        Call:  GradientBoostReg(xTrain, xTest, yTrain, yTest).gradient_boosting_regressor(self.xTrain, xTest, yTrain, yTest)\n",
    "        Unittest methods with basic hand-made dataset\n",
    "        '''\n",
    "        from sklearn import ensemble\n",
    "\n",
    "        # 1- unparametrize GBR model\n",
    "        self.GBMModel = ensemble.GradientBoostingRegressor(n_estimators=self.NUMBER_ESTIMATORS,\n",
    "                                                      max_depth=self.MAX_DEPTH,\n",
    "                                                      learning_rate=self.LEARN_RATE,\n",
    "                                                      subsample=self.SUB_SAMPLE,\n",
    "                                                      loss=self.LOSS_FUNCTION)\n",
    "        # 2- params_space\n",
    "        \n",
    "        \n",
    "        # 3- hyperparams optimization \n",
    "        \n",
    "        # 4- train model by fitting it on train data and target\n",
    "        self.GBMModel.fit(self.xTrain, self.yTrain) #still features non float format issue\n",
    "        \n",
    "        # 5- best params\n",
    "    \n",
    "    def compute_mse_list(self):\n",
    "        ''' \n",
    "        Compute MSE on test set\n",
    "        Dependency : gradient_boosting_regressor\n",
    "        '''\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        trained_ml_model = self.GBMModel\n",
    "\n",
    "        best_of_sets_predictions = trained_ml_model.staged_predict(self.xTest) #check method staged_predict in model\n",
    "\n",
    "        self.target_predictions = np.around(self.GBMModel.predict(xTest))\n",
    "        \n",
    "        for predic in best_of_sets_predictions:\n",
    "            self.mse_list.append(mean_squared_error(self.yTest,predic))\n",
    "\n",
    "        print(\"MSE for model:\")\n",
    "        print(\"MSE min value: %s\"%str(min(self.mse_list)))\n",
    "        print(\"optimal number of trees: %s\"%str(self.mse_list.index(min(self.mse_list))))\n",
    "\n",
    "    def normalize_feature_importances(self):\n",
    "        '''\n",
    "        Dependency : compute_mse_list\n",
    "        '''\n",
    "        print('GBMModel.feature_importances_ %s'%str(self.GBMModel.feature_importances_))\n",
    "        \n",
    "        featureImportance = GBMInstance.GBMModel.feature_importances_\n",
    "\n",
    "        # Normalize feature importances by max(feature_importance)\n",
    "        self.normalFeatureImportances = featureImportance/featureImportance.max()\n",
    "        \n",
    "    def plot_train_test_errors(self):\n",
    "        '''\n",
    "        Plot training and test errors vs number of trees in ensemble\n",
    "        Dependency : compute_mse_list\n",
    "        '''\n",
    "        # GBMInstance.plot_train_test_errors()\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, self.numberEstimators + 1),\n",
    "                 GBMInstance.GBMModel.train_score_,\n",
    "                 label='Training Set MSE')\n",
    "\n",
    "        plt.plot(range(1, self.numberEstimators + 1),\n",
    "                 GBMInstance.mse_list,\n",
    "                 label='Test Set MSE')\n",
    "\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlabel('Number of Trees in ensemble')\n",
    "        plt.ylabel('Mean Squared Error')\n",
    "        plt.show()\n",
    "       \n",
    "    def plot_feature_importance(self):\n",
    "        ''' Plot Feature Importance '''\n",
    "        self.normalize_feature_importances()\n",
    "        \n",
    "        # sort them by ascending order\n",
    "        indexes_sorted_FI = np.argsort(self.normalFeatureImportances)\n",
    "        barPos = np.arange(indexes_sorted_FI.shape[0]) + .5\n",
    "        plt.barh(barPos, GBMInstance.normalFeatureImportances[indexes_sorted_FI], align='center')\n",
    "        plt.yticks(barPos, data_best_of.columns[indexes_sorted_FI])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.show()\n",
    "\n",
    "        print('list of variable importances by increasing order: ')\n",
    "        for feature_name in data_best_of.columns[indexes_sorted_FI]:\n",
    "            print(feature_name)\n",
    "            \n",
    "class RandomForestClassifier(TreeBasedModels):\n",
    "    '''\n",
    "    Purpose: model used for asessing feature importance\n",
    "    Reference: https://www.programcreek.com/python/example/83260/sklearn.ensemble.GradientBoostingClassifier\n",
    "    Called by: OverallTreeBasedFeatureImportance\n",
    "    gbc_model =  GradientBoostedClassifer(XTrain, Xtest, yTrain, yTest)\n",
    "    '''\n",
    "    CRITERION = 'gini'\n",
    "    MIN_SAMPLES_SPLIT = 2 # default value\n",
    "    MIN_SAMPLES_LEAF = 1 # default value\n",
    "    \n",
    "    def __init__(self, XTrain, Xtest, yTrain, yTest):\n",
    "        self.class_model = 'gradient-boosted-classifier'\n",
    "        # les valeurs ne passent pas par heritage: a voir\n",
    "        self.XTrain = XTrain\n",
    "        self.XTest = XTest\n",
    "        self.yTrain = yTrain\n",
    "        self.yTest = yTest\n",
    "        if isinstance(XTest, pd.DataFrame):\n",
    "            self.X_test = XTest.values\n",
    "            self.y_test = yTest.values\n",
    "        else:\n",
    "            self.X_test = XTest\n",
    "            self.y_test = yTest\n",
    "        self.MAX_DEPTH = 20\n",
    "        self.NUMBER_ESTIMATORS = 100\n",
    "        \n",
    "    def random_forest_classifier(self):\n",
    "        '''\n",
    "        Purpose: build a GBC with valued parameters\n",
    "        Reference: https://www.programcreek.com/python/example/83260/sklearn.ensemble.GradientBoostingClassifier\n",
    "        '''\n",
    "        from sklearn import ensemble\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sn\n",
    "        from pretty_cm_plot import plot_confusion_matrix_from_data\n",
    "        from sklearn.metrics import f1_score\n",
    "        from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "            \n",
    "        # weight_list\n",
    "        weight_list = [] # see this option later on!\n",
    "        \n",
    "        # -1 semi-parametrize GBC model\n",
    "        RFC_classifier = ensemble.RandomForestClassifier(criterion=self.CRITERION, \n",
    "                                         random_state=132134,\n",
    "                                         min_samples_split=self.MIN_SAMPLES_SPLIT,\n",
    "                                         min_samples_leaf=self.MIN_SAMPLES_LEAF)\n",
    "\n",
    "        # 2- best hyper-parameters\n",
    "        #datascience.stackexchange\n",
    "        params_space = {\n",
    "            'n_estimators': [10, 30, 50],\n",
    "            'max_depth': [4, 6, 8]\n",
    "        }\n",
    "        \n",
    "        RFC_gridsearch = GridSearchCV(estimator=RFC_classifier,\n",
    "                                    param_grid=params_space,\n",
    "                                    cv=3)\n",
    "        \n",
    "        # 3- model fitting in train data and target\n",
    "        RFC_gridsearch.fit(self.XTrain, self.yTrain)\n",
    "        print('MLP best_params_ %s'%str(RFC_gridsearch.best_params_))\n",
    "        q=retydfg\n",
    "\n",
    "class GBCclassifier(TreeBasedModels):\n",
    "    '''\n",
    "    Purpose: model used for asessing feature importance\n",
    "    Reference: https://www.programcreek.com/python/example/83260/sklearn.ensemble.GradientBoostingClassifier\n",
    "    Called by: OverallTreeBasedFeatureImportance\n",
    "    gbc_model =  GradientBoostedClassifer(XTrain, Xtest, yTrain, yTest)\n",
    "    '''\n",
    "    LOSS = 'deviance'\n",
    "    MIN_SAMPLES_SPLIT = 2 # default value\n",
    "    MIN_SAMPLES_LEAF = 1 # default value\n",
    "    \n",
    "    def __init__(self, XTrain, Xtest, yTrain, yTest):\n",
    "        self.class_model = 'gradient-boosted-classifier'\n",
    "        # les valeurs ne passent pas par heritage: a voir\n",
    "        self.XTrain = XTrain\n",
    "        self.XTest = XTest\n",
    "        self.yTrain = yTrain\n",
    "        self.yTest = yTest\n",
    "        if isinstance(XTest, pd.DataFrame):\n",
    "            self.X_test = XTest.values\n",
    "            self.y_test = yTest.values\n",
    "        else:\n",
    "            self.X_test = XTest\n",
    "            self.y_test = yTest\n",
    "        \n",
    "    def gradient_boosting_classifier(self):\n",
    "        '''\n",
    "        Purpose: build a GBC with valued parameters\n",
    "        Reference: https://www.programcreek.com/python/example/83260/sklearn.ensemble.GradientBoostingClassifier\n",
    "        '''\n",
    "        from sklearn import ensemble\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sn\n",
    "        from pretty_cm_plot import plot_confusion_matrix_from_data\n",
    "        from sklearn.model_selection import RandomizedSearchCV\n",
    "        \n",
    "        print('gradient_boosting_classifier LOSS %s'%str(self.LOSS))\n",
    "        print('gradient_boosting_classifier NUMBER_ESTIMATORS %s'%str(self.NUMBER_ESTIMATORS))\n",
    "        print('gradient_boosting_classifier LAERN_RATE %s'%str(self.LEARN_RATE))\n",
    "        print('gradient_boosting_classifier MIN_SAMPLES_SPLIT %s'%str(self.MIN_SAMPLES_SPLIT))\n",
    "        \n",
    "        # weight_list\n",
    "        weight_list = [] # see this option later on!\n",
    "        \n",
    "        # 1- semi-parametrized GBC model\n",
    "        GBC_classifier = ensemble.GradientBoostingClassifier(loss=self.LOSS, \n",
    "                                         random_state=0,\n",
    "                                         min_samples_leaf=self.MIN_SAMPLES_LEAF,\n",
    "                                         subsample=self.SUB_SAMPLE)\n",
    "\n",
    "        # 2- best hyper-parameters\n",
    "        #datascience.stackexchange\n",
    "        params_space = {\n",
    "            'n_estimators': [10, 30, 50],\n",
    "            'learning_rate': [0.001, 0.01],\n",
    "            'max_depth': [4, 6, 8]\n",
    "        }\n",
    "        \n",
    "        GBC_random = RandomizedSearchCV(estimator=GBC_classifier,\n",
    "                                        param_distributions=params_space,\n",
    "                                        cv=3)\n",
    "        # 3- model fitting in train data and target\n",
    "        GBC_random.fit(self.XTrain, self.yTrain)\n",
    "        print('MLP best_params_ %s'%str(GBC_random.best_params_))\n",
    "        # MLP best_params_ {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.01}\n",
    "        \n",
    "\n",
    "#///////////////////////////////////////\n",
    "class OverallTreeBasedFeatureImportance():\n",
    "    '''\n",
    "    NEED TO BE CHECKED MORE\n",
    "    Purpose: build, train, test, assess several models for feature importance assessment\n",
    "    '''\n",
    "    FI = 'feature_importances'\n",
    "    COEF = 'coef'\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        parametrize series of models for FI\n",
    "        '''\n",
    "        self.class_model = 'overall_treebase_feature_importances'\n",
    "        # ensemble modeling aggregating results from different models by voting output\n",
    "        self.clfs = {'RandomForestClassifier': self.FI,\n",
    "                'ExtraTreesClassifier': self.FI,\n",
    "                'AdaBoostClassifier': self.FI,\n",
    "                'LogisticRegression': self.COEF,\n",
    "                'svm.SVC': self.COEF,\n",
    "                'GradientBoostingClassifier': self.FI,\n",
    "                'GaussianNB': None,\n",
    "                'DecisionTreeClassifier': self.FI,\n",
    "                'SGDClassifier': self.COEF,\n",
    "                'KNeighborsClassifier': None,\n",
    "                'linear.SVC': self.COEF}\n",
    "\n",
    "    # def train_models\n",
    "        \n",
    "    def get_feature_importance(self):\n",
    "        '''\n",
    "        clf has to be a trained model\n",
    "        '''\n",
    "        if clfs[model_name] == self.FI:\n",
    "            return  list(clf.feature_importances_)\n",
    "        elif clfs[model_name] == self.COEF:\n",
    "            return  list(clf.coef_.tolist())\n",
    "        else:\n",
    "            return None \n",
    "             \n",
    "#///////////////////////////////////////\n",
    "'''\n",
    "Theorie sur les ANN et DL: livre Comprendre le DL\n",
    "* predicteurs et classifieurs:\n",
    "    - train a linear predictor:  usd=c*euro\n",
    "    c=c0 ->err0=abs(usd-c0*euro)\n",
    "    \n",
    "'''\n",
    "class DeepLearningModels(MLmodels):\n",
    "    '''\n",
    "    Keras DL models\n",
    "    '''\n",
    "    def __init__(self, XTrain, XTest, yTrain, yTest):\n",
    "        '''\n",
    "        heritage on X,yTrain,Test\n",
    "        '''\n",
    "        self.class_model = 'deep-learning-models'\n",
    "           \n",
    "            \n",
    "class DLApplier(MLmodels):\n",
    "    '''\n",
    "    Purpose: to apply keras_regressor onto a dataset\n",
    "    Build the complete pipeline\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, XTrain, XTest, yTrain, yTest, models_list):\n",
    "        self.class_model = 'dl-applier'\n",
    "        self.SUCCESS = 'SUCESS'\n",
    "        self.FAILED = 'FAILED'\n",
    "        self.models_list = models_list\n",
    "        \n",
    "    def apply_keras_model(self):\n",
    "        ''' Purpose: in cas model tag is keras_regressor then do this'''\n",
    "        try:\n",
    "            # get an instance of keras regressor model\n",
    "            keras_model = KerasReg(XTrain, XTest, yTrain, yTest)\n",
    "            \n",
    "            # apply keras_regressor\n",
    "            keras_model.keras_regressor()\n",
    "        except:\n",
    "            print('DLApplier issue: %s'%self.FAILED)\n",
    "            raise\n",
    "        \n",
    "        return self.SUCCESS\n",
    "\n",
    "# MultiLayer perceptron model\n",
    "class MLPclassifier(MLmodels):\n",
    "    ''' model for MLP building and fitting '''\n",
    "    \n",
    "    def __init__(self, XTrain, XTest, yTrain, yTest):\n",
    "        self.class_model = 'mlp_classifier'\n",
    "        self.XTrain = XTrain\n",
    "        self.XTest = XTest\n",
    "        self.yTrain = yTrain\n",
    "        self.yTest = yTest\n",
    "        if isinstance(XTrain, pd.DataFrame):\n",
    "            self.X_train = XTrain.values\n",
    "            self.y_train = yTrain.values\n",
    "        else:\n",
    "            self.X_train = XTrain\n",
    "            self.y_train = yTrain\n",
    "        if isinstance(XTest, pd.DataFrame):\n",
    "            self.X_test = XTest.values\n",
    "            self.y_test = yTest.values\n",
    "        else:\n",
    "            self.X_test = XTest\n",
    "            self.y_test = yTest\n",
    "        \n",
    "    def mlp_classifier(self):\n",
    "        ''' from ref on sklearn '''\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sn\n",
    "        from pretty_cm_plot import plot_confusion_matrix_from_data\n",
    "        from sklearn.model_selection import RandomizedSearchCV\n",
    "        \n",
    "        # 1- unparametrized model: see for hyperparameter optim.\n",
    "        MLPclassifier = MLPClassifier()\n",
    "        \n",
    "        # 2- best hyper-parameters\n",
    "        #datascience.stackexchange\n",
    "        params_space = {\n",
    "            'hidden_layer_sizes': [(7,15,5), (5,8,3), (11,7,5)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.001],\n",
    "            'learning_rate': ['constant','adaptive'], \n",
    "        }\n",
    "        \n",
    "        mlp_random = RandomizedSearchCV(estimator=MLPclassifier,\n",
    "                                        param_distributions=params_space,\n",
    "                                        cv=3)\n",
    "        # 3- model fitting in train data and target\n",
    "        mlp_random.fit(self.X_train, self.y_train)\n",
    "        print('MLP best_params_ %s'%str(mlp_random.best_params_))\n",
    "              \n",
    "\n",
    "#SVMmodel\n",
    "class SVMclassifier(MLmodels):\n",
    "    ''' model for SVM building and fitting '''\n",
    "    \n",
    "    def __init__(self, XTrain, XTest, yTrain, yTest):\n",
    "        self.class_model = 'mlp_classifier'\n",
    "        self.XTrain = XTrain\n",
    "        self.XTest = XTest\n",
    "        self.yTrain = yTrain\n",
    "        self.yTest = yTest\n",
    "        if isinstance(XTrain, pd.DataFrame):\n",
    "            self.X_train = XTrain.values\n",
    "            self.y_train = yTrain.values\n",
    "        else:\n",
    "            self.X_train = XTrain\n",
    "            self.y_train = yTrain\n",
    "        if isinstance(XTest, pd.DataFrame):\n",
    "            self.X_test = XTest.values\n",
    "            self.y_test = yTest.values\n",
    "        else:\n",
    "            self.X_test = XTest\n",
    "            self.y_test = yTest\n",
    "        \n",
    "    def svm_classifier(self):\n",
    "        ''' from ref on sklearn '''\n",
    "        from sklearn import svm\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sn\n",
    "        from pretty_cm_plot import plot_confusion_matrix_from_data\n",
    "        \n",
    "        # 1- parametrize model: see for hyperparameter optim.\n",
    "        SVMclassifier = svm.SVC(gamma='scale')\n",
    "        \n",
    "        # 2- train model on Xtrain and yTrain\n",
    "        SVMclassifier.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # 3- predictions delivered by model\n",
    "        SVM_pred = SVMclassifier.predict(self.XTest)\n",
    "        \n",
    "        # 4- Performance metrics: confusion matrix\n",
    "        SVM_conf_mat = confusion_matrix(self.y_test, SVM_pred)\n",
    "        print('SVM conf_mat:\\n %s'%SVM_conf_mat)\n",
    "        \n",
    "        # 5- plot confusion matrix\n",
    "        if(len(self.y_test) > 10):\n",
    "            fz=9; figsize=[14,14]\n",
    "            plot_confusion_matrix_from_data(self.y_test,\n",
    "                                            SVM_pred,\n",
    "                                            fz, figsize)\n",
    "        \n",
    "        # 6- Perf metrics: F1-score\n",
    "        from sklearn.metrics import f1_score\n",
    "        SVM_F1_score = f1_score(self.y_test, SVM_pred, average='micro')\n",
    "        print('MLP F1-score %s'%str(SVM_F1_score))\n",
    "        \n",
    "        # 7- Perf metrics: CV\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        print('cv_scores %s'%str(cross_val_score(SVMclassifier,\n",
    "                                                 self.X_test,\n",
    "                                                 self.y_test,\n",
    "                                                 scoring='recall_macro',cv=2)))\n",
    "        \n",
    "        return SVM_pred, SVM_conf_mat, SVM_F1_score\n",
    "\n",
    "# XGboost    \n",
    "class XGBclassifier(MLmodels):\n",
    "    \n",
    "    def __init__(self, XTrain, XTest, yTrain, yTest):\n",
    "        self.class_model = 'mlp_classifier'\n",
    "        self.XTrain = XTrain\n",
    "        self.XTest = XTest\n",
    "        self.yTrain = yTrain\n",
    "        self.yTest = yTest\n",
    "        if isinstance(XTrain, pd.DataFrame):\n",
    "            self.X_train = XTrain.values\n",
    "            self.y_train = yTrain.values\n",
    "        else:\n",
    "            self.X_train = XTrain\n",
    "            self.y_train = yTrain\n",
    "        if isinstance(XTest, pd.DataFrame):\n",
    "            self.X_test = XTest.values\n",
    "            self.y_test = yTest.values\n",
    "        else:\n",
    "            self.X_test = XTest\n",
    "            self.y_test = yTest\n",
    "        \n",
    "    def xgb_classifier(self):\n",
    "        from xgboost import XGBClassifier\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sn\n",
    "        from pretty_cm_plot import plot_confusion_matrix_from_data\n",
    "\n",
    "        # 1- parametrize model: see for hyperparameter optim. max_depth=4 is optiomal for target =f(minutes)\n",
    "        XGBclassifier = XGBClassifier(max_depth=4,\n",
    "                                      gamma=10,\n",
    "                                      objective='binary:logistic',\n",
    "                                      normalize_type='forest',\n",
    "                                      num_parallel_tree=4,\n",
    "                                      eval_metric='auc')\n",
    "\n",
    "        # 2- train model on Xtrain and yTrain\n",
    "        XGBclassifier.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # 3- prediction from model\n",
    "        XGB_pred = XGBclassifier.predict(self.X_test)\n",
    "\n",
    "        # 4- Performance metrics: confusion matrix\n",
    "        XGB_conf_mat = confusion_matrix(self.y_test, XGB_pred)\n",
    "        print('XGB conf_mat:\\n %s'%XGB_conf_mat)\n",
    "        \n",
    "        # 5- plot confusion matrix\n",
    "        if(len(self.y_test) > 10):\n",
    "            fz=9; figsize=[14,14]\n",
    "            plot_confusion_matrix_from_data(self.y_test,\n",
    "                                            XGB_pred,\n",
    "                                            fz, figsize)\n",
    "        \n",
    "        # 6- accuracy score\n",
    "        accuracy = accuracy_score(self.y_test, XGB_pred)\n",
    "        print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "        return XGB_pred, XGB_conf_mat, accuracy\n",
    "    \n",
    "#//////////////////////////////////\n",
    "'''\n",
    "To split class above into 4 libs:\n",
    "1- Linear Models\n",
    "  - Regressor\n",
    "  - Classifiers\n",
    "2- TreeBased Models\n",
    "  - Regressor\n",
    "  - Classifier\n",
    "3- Keras DL\n",
    "  - Regressor\n",
    "  - Classifier\n",
    "'''\n",
    "################### MAIN PART of package #################\n",
    "#preproc seps to be embedded into one pipeline: pipeline_from_csv_to_X_y_arrays\n",
    "\n",
    "# Part A: read dataset - Feature engineering - Build X, y, train,test\n",
    "from pre_proc_lib_12dec import *\n",
    "PREPROCinstance = PreProcLib('ATP.csv') #, target_choosen='minutes')\n",
    "'''\n",
    "test normalization numerical features\n",
    "'''\n",
    "data, target, XTrain_tmp, XTest_tmp, yTrain_tmp, yTest_tmp = \\\n",
    "    PREPROCinstance.full_pre_proc_from_file_to_X_y_train_test('ATP.csv')\n",
    "\n",
    "''' !!!\n",
    "type(XTrain) <class 'pandas.core.frame.DataFrame'>\n",
    "type(yTrain) <class 'pandas.core.series.Series'>\n",
    "'''\n",
    "XTrain = XTrain_tmp.values\n",
    "yTrain = yTrain_tmp.as_matrix()\n",
    "XTest = XTest_tmp.values\n",
    "yTest = yTest_tmp.as_matrix()\n",
    "\n",
    "'''\n",
    "data should have columns in it right?\n",
    "data       \n",
    "--> draw_size match_num winner_ht winner_age winner_rank  \\\n",
    "77000         32         1       178    21.7714          33   \n",
    "77001         32         2       180    27.1978         441   \n",
    "77002         32         3       168    22.7543         208   \n",
    "'''\n",
    "\n",
    "print('data %s'%str(data))\n",
    "print('target %s'%str(target))\n",
    "print('yTrain.shape() %s'%str(yTrain.shape))\n",
    "print('XTrain.shape() %s'%str(XTrain.shape))\n",
    "print('XTrain %s'%XTrain[:10][:])\n",
    "print('yTrain %s'%yTrain[:10])\n",
    "print('XTest %s'%XTest[:10][:])\n",
    "print('yTest %s'%yTest)\n",
    "print('best_of' in data)\n",
    "print('best_of' in target)\n",
    "print('best_of' in XTrain)\n",
    "print('best_of' in yTrain)\n",
    "print('loser_rank_points in XTrain %s'%'loser_rank_points in XTrain' in XTrain)\n",
    "print('loser_rank_points in yTrain %s'%'loser_rank_points in yTrain' in yTrain)\n",
    "print('loser_rank_points in XTest %s'%'loser_rank_points in XTest' in XTest)\n",
    "print('loser_rank_points in yTest %s'%'loser_rank_points in yTest' in yTest)\n",
    "print('type(XTrain) %s'%type(XTrain))\n",
    "print('type(yTrain) %s'%type(yTrain))\n",
    "\n",
    "# Part B: ML part classification\n",
    "#--- RFC model: it works about with minutes ---\n",
    "RFCmodel = RandomForestClassifier(XTrain, XTest, yTrain, yTest)\n",
    "RFC_pred, RFC_cm, RFC_f1_score = RFCmodel.random_forest_classifier()\n",
    "'''\n",
    "encouraging with normalize_numerical_variables in pre_proc_lib_12dec!!\n",
    "RFC conf_mat:\n",
    " [[5246 4000]\n",
    " [4219 7207]]\n",
    " !! strangely enough: same results when normalization not applied in pre_proc_lib_12dec def overall_operations\n",
    " See how ...\n",
    "'''\n",
    "'''\n",
    "#--- GBC model ---\n",
    "GBCmodel = GBCclassifier(XTrain, XTest, yTrain, yTest)\n",
    "GBC_pred, GBC_cm, GBC_F1_score = GBCmodel.gradient_boosting_classifier()\n",
    "'''\n",
    "'''\n",
    "check the issue with GBC model poor predictions\n",
    "'''\n",
    "'''\n",
    "#--- XGB model ---\n",
    "XGBmodel = XGBclassifier(XTrain, XTest, yTrain, yTest)\n",
    "XGB_pred, XGB_cm, XGB_accuracy_score = XGBmodel.xgb_classifier()\n",
    "'''\n",
    "'''\n",
    "with normalize_numerical_features in pre_proc_12dec: encouraging:\n",
    "XGB conf_mat:\n",
    " [[5536 3710]\n",
    " [4411 7015]]\n",
    " !! strangely enough: same results when normalization not applied in pre_proc_lib_12dec def overall_operations\n",
    " See how ...\n",
    " Here normalization has no impact\n",
    "'''\n",
    "\n",
    "'''\n",
    "#--- MLP model ---\n",
    "MLPmodel = MLPclassifier(XTrain, XTest, yTrain, yTest)\n",
    "MLP_pred, MLP_cm, MLP_F1_score = MLPmodel.mlp_classifier()\n",
    "'''\n",
    "'''\n",
    "MLP fonctionne avec features normalized et target = classes from minutes\n",
    "layers_tuple: (20, 10, 4)\n",
    "MLP conf_mat:\n",
    " [[5532 3714]\n",
    " [4478 6948]]\n",
    " accuracy = \n",
    " MLP F1-score 0.6037151702786377\n",
    "cv_scores [0.61779745 0.60768909]\n",
    "\n",
    "layers_tuple=(15,9)\n",
    "MLP conf_mat:\n",
    " [[6228 3018]\n",
    " [5232 6194]]\n",
    " \n",
    "layers_tuple=(15,5)\n",
    " MLP conf_mat:\n",
    " [[4527 4719]\n",
    " [3580 7846]]\n",
    " \n",
    "layers = (25,15,5)\n",
    "MLP conf_mat:\n",
    " [[6492 2754]\n",
    " [5477 5949]]\n",
    " \n",
    "layers = (7,15,5)\n",
    "MLP conf_mat:\n",
    " [[6170 3076]\n",
    " [5093 6333]] -> min total wrong class\n",
    " \n",
    "MLP conf_mat: with optim params_space\n",
    " [[5501 3745]\n",
    " [4480 6946]]\n",
    "'''\n",
    "\n",
    "'''\n",
    "check the issue with GBC model poor predictions\n",
    "'''\n",
    "'''\n",
    "#--- SVM model: marche pas ---\n",
    "SVMmodel = SVMclassifier(XTrain, XTest, yTrain, yTest)\n",
    "SVM_pred, SVM_cm, SVM_F1_score = SVMmodel.svm_classifier()\n",
    "'''\n",
    "\n",
    "# METRIC PERFORMANCE - TO BE SET IN A PY LIB\n",
    "# RFCmodel F1-score macro= 0.207282055704\n",
    "# RFCmodel F1-score weighted= 0.514761028483: pas mal\n",
    "# RFCmodel F1-score 0.636500933985: bien!\n",
    "\n",
    "# 4- average_precision_score\n",
    "#from sklearn.metrics import average_precision_score\n",
    "#print('RFCmodel accuracy_score %s'%str(average_precision_score(y_test, y_scores)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
